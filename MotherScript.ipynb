{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T12:37:08.904433Z",
     "iopub.status.busy": "2022-09-15T12:37:08.904028Z",
     "iopub.status.idle": "2022-09-15T12:37:09.147210Z",
     "shell.execute_reply": "2022-09-15T12:37:09.146517Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "\n",
    "# envs\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d762cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T12:37:09.150448Z",
     "iopub.status.busy": "2022-09-15T12:37:09.150165Z",
     "iopub.status.idle": "2022-09-15T12:37:09.154397Z",
     "shell.execute_reply": "2022-09-15T12:37:09.153772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/runner/work/update/update'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T12:37:09.158561Z",
     "iopub.status.busy": "2022-09-15T12:37:09.158357Z",
     "iopub.status.idle": "2022-09-15T12:37:50.699371Z",
     "shell.execute_reply": "2022-09-15T12:37:50.698814Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to check:  BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\n",
      "previous log found: 2022-09-14 12:34\n",
      "difference in execution is: 1.0022 days\n",
      "needed difference to execute: 0.625 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "d칤a de la semana hora local UTC = 3\n",
      "hoy es 2022-09-15\n",
      "Hora actual en UTC = 12:37:09\n",
      "envs failed to load\n",
      "\n",
      "MAPA DEL D칈A:\n",
      "Tasa de mortalidad infantil (< 1 a침o), 2016 (por 1,000 nacidos vivos) \n",
      "\n",
      "Municipio m치s 치lto: Caripuyo con 70.3\n",
      "Municipio m치s bajo: Boyuibe con 10.9\n",
      "\n",
      "(Fuente: SDSN Bolivia)\n",
      "\n",
      "TWEET SUCCESFUL!! \n",
      "... t'was a SUCCESS! :)\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb \n",
      "\n",
      "游땖游땖游땖游땖游땖游땖游땖游땖 NEXT 游땖游땖游땖游땖游땖游땖游땖游땖游땖\n",
      "\n",
      "\n",
      "starting to check:  BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\n",
      "previous log found: 2022-09-14 12:35\n",
      "difference in execution is: 1.0015 days\n",
      "needed difference to execute: 0.5833 days\n",
      "Executtion:  True ... STARTING NOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state Virginia server backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d칤a de la semana hora local UTC = 3\n",
      "hoy es 2022-09-15\n",
      "Hora actual en UTC = 12:37:12\n",
      "envs failed to load\n",
      "SH.XPD.OOPC.CH.ZS\n"
     ]
    },
    {
     "ename": "APIResponseError",
     "evalue": "APIError: JSON decoding error (https://api.worldbank.org/v2/en/sources/2/series/SH.XPD.OOPC.CH.ZS?per_page=1000&page=1&format=json)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/requests/models.py:960\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001b[39;00m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# used.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 9 (char 9)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:533\u001b[0m, in \u001b[0;36m_queryAPI\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/requests/models.py:968\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 968\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 9 (char 9)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIResponseError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1716/3201860860.py:38\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTWEET SUCCESFUL!! \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mpost_wb_fig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/ipykernel_1716/3201860860.py:16\u001b[0m, in \u001b[0;36mpost_wb_fig\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(indicator)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# get indicator title\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[43mwb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtable()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     17\u001b[0m title_plus \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mgoogle(title, from_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, to_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m title_plus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBolivia: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m title_plus\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/series.py:85\u001b[0m, in \u001b[0;36minfo\u001b[0;34m(id, q, topic, db)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, q\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, topic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, db\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124;03m'''Print a user report of series. This can be time consuming\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    for large databases like the WDI if 'all' series are requested.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:190\u001b[0m, in \u001b[0;36mFeatureset.__init__\u001b[0;34m(self, items, columns)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, items, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124;03m''' can be initialized with any iterable\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m columns \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/series.py:40\u001b[0m, in \u001b[0;36mlist\u001b[0;34m(id, q, topic, db)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m topics\n\u001b[1;32m     38\u001b[0m q,fullSearch \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mqget(q)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m w\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mfeatures(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m'\u001b[39m, w\u001b[38;5;241m.\u001b[39mqueryParam(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m'\u001b[39m, db\u001b[38;5;241m=\u001b[39mdb), db\u001b[38;5;241m=\u001b[39mdb):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mqmatch(q, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m], fullSearch):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m row\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:322\u001b[0m, in \u001b[0;36mrefetch\u001b[0;34m(url, variables, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m url2 \u001b[38;5;129;01min\u001b[39;00m _refetch_url(url, variables[\u001b[38;5;241m0\u001b[39m], variables[\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 322\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m fetch(url2, params, concepts, lang):\n\u001b[1;32m    323\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m row\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:281\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(url, params, concepts, lang)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m totalRecords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m recordsRead \u001b[38;5;241m<\u001b[39m totalRecords:\n\u001b[1;32m    280\u001b[0m     url_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(endpoint, lang, url, urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlencode(params_))\n\u001b[0;32m--> 281\u001b[0m     (hdr,result) \u001b[38;5;241m=\u001b[39m \u001b[43m_queryAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m totalRecords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m         totalRecords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(hdr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:535\u001b[0m, in \u001b[0;36m_queryAPI\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    533\u001b[0m     result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIResponseError(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJSON decoding error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    537\u001b[0m hdr \u001b[38;5;241m=\u001b[39m _responseHeader(url, result)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hdr\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mAPIResponseError\u001b[0m: APIError: JSON decoding error (https://api.worldbank.org/v2/en/sources/2/series/SH.XPD.OOPC.CH.ZS?per_page=1000&page=1&format=json)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... t'was a FAILURE. :(\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb \n",
      "\n",
      "游땖游땖游땖游땖游땖游땖游땖游땖 NEXT 游땖游땖游땖游땖游땖游땖游땖游땖游땖\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\n",
      "previous log found: 2022-09-14 18:21\n",
      "difference in execution is: 0.7616 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb \n",
      "\n",
      "游땖游땖游땖游땖游땖游땖游땖游땖 NEXT 游땖游땖游땖游땖游땖游땖游땖游땖游땖\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\n",
      "previous log found: 2022-09-14 20:19\n",
      "difference in execution is: 0.6796 days\n",
      "needed difference to execute: 0.25 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "envs failed to load\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures 游녢\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! 游뱄\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Saint Helena, Ascension and Tristan da Cunha\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions British Indian Ocean Territory\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Iraq\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Austria\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Holy See (Vatican City State)\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Turkmenistan\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 66\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/TKM_Turkmenistan/figures/TKM_relative_totals.png',\n",
       " 'country_data/TKM_Turkmenistan/figures/TKM_GCP_Country_Highlight.png',\n",
       " 'country_data/TKM_Turkmenistan/figures/TKM_GCP_1.png',\n",
       " 'country_data/TKM_Turkmenistan/figures/TKM_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Antigua and Barbuda\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Botswana\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Kyrgyzstan\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Greenland\"\n",
      " > found 4 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 67\n",
      " > 1 usernames filtered out\n",
      " > retweets removed: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/GRL_Greenland/figures/GRL_relative_totals.png',\n",
       " 'country_data/GRL_Greenland/figures/GRL_GCP_Country_Highlight.png',\n",
       " 'country_data/GRL_Greenland/figures/GRL_GCP_1.png',\n",
       " 'country_data/GRL_Greenland/figures/GRL_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [True, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "... t'was a SUCCESS! :)\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb \n",
      "\n",
      "游땖游땖游땖游땖游땖游땖游땖游땖 NEXT 游땖游땖游땖游땖游땖游땖游땖游땖游땖\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/random_fig/random_fig.ipynb\n",
      "previous log found: 2022-09-14 18:21\n",
      "difference in execution is: 0.7617 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/random_fig/random_fig.ipynb \n",
      "\n",
      "游땖游땖游땖游땖游땖游땖游땖游땖 NEXT 游땖游땖游땖游땖游땖游땖游땖游땖游땖\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\n",
      "previous log found: 2022-09-13 14:23\n",
      "difference in execution is: 1.927 days\n",
      "needed difference to execute: 2 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb \n",
      "\n",
      "游땖游땖游땖游땖游땖游땖游땖游땖 NEXT 游땖游땖游땖游땖游땖游땖游땖游땖游땖\n",
      "\n",
      "\n",
      "游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩\n",
      "               FINITO\n",
      "游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting to check: \", notebook_path)\n",
    "    \n",
    "\n",
    "\n",
    "    # if there is no schedule, run immediately\n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "\n",
    "\n",
    "    # else run on a schedule based on last execution time\n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = [\"2002-07-16 18:32\",np.nan]\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        import datetime\n",
    "        now = datetime.datetime.now()\n",
    "        last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # check diff\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE?\n",
    "\n",
    "\n",
    "    # EXECUTE TRUE\n",
    "    if EXECUTE == True:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... STARTING NOW\")\n",
    "\n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        # try to run script, if it fails, it fails\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"... t'was a SUCCESS! :)\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"... t'was a FAILURE. :(\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE FALSE\n",
    "    elif EXECUTE == False:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... DID NOT EXECUTE NOR LOG\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Finished: \", notebook_path, \"\\n\\n游땖游땖游땖游땖游땖游땖游땖游땖 NEXT 游땖游땖游땖游땖游땖游땖游땖游땖游땖\\n\\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "###################### SCHEDULE #######################\n",
    "########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### BOLIGRAFICA #####\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_covid_replies/covid_reply.ipynb\", schedule_in_days= 12/24)\n",
    "SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\", schedule_in_days=15/24)\n",
    "SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\", schedule_in_days=14/24)\n",
    "\n",
    "###### GREENHOUSE DATA #####\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\", schedule_in_days = 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/random_fig/random_fig.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\", schedule_in_days = 2)\n",
    "\n",
    "\n",
    "print(\"游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩\\n               FINITO\\n游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩游냩\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be59bc6-1940-45e1-9e81-478b87935bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3879f593f72178d4cdaa5d992027cc0eafe2075e6c7e6c2da0f0dd376bbd7072"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
