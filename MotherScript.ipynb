{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4a0a40-8b47-4681-bb18-f475c239f1ff",
   "metadata": {},
   "source": [
    "Already exists:\n",
    "- Boligrafica Twitter Tweepy\n",
    "- Greenhouse Summon\n",
    "- NOAA Data update GHD\n",
    "\n",
    "Want to create:\n",
    "- GFW - Datos Bolivia Deforestacion / Incendios\n",
    "- Other twitter bots!??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef13b2-37fc-4b5e-8d6f-2f0a3d0982d7",
   "metadata": {},
   "source": [
    "Types of conditions:\n",
    "- Runs on a schedule \n",
    "  - once every week (like boligrafica)\n",
    "  - 4 times a day (like greenhouse summon)\n",
    "- Runs if it has detected updated data (if new data, run)\n",
    "  - Like NOAA data in GHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T08:28:42.919044Z",
     "iopub.status.busy": "2022-08-05T08:28:42.918711Z",
     "iopub.status.idle": "2022-08-05T08:28:43.268488Z",
     "shell.execute_reply": "2022-08-05T08:28:43.267517Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython import get_ipython\n",
    "\n",
    "# environmental secrets when working locally\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0908834-aaeb-4413-a8d9-3086674bc2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T08:28:43.273660Z",
     "iopub.status.busy": "2022-08-05T08:28:43.273261Z",
     "iopub.status.idle": "2022-08-05T08:28:43.277305Z",
     "shell.execute_reply": "2022-08-05T08:28:43.276381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NEW_DATA_RUNNER():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T08:28:43.281618Z",
     "iopub.status.busy": "2022-08-05T08:28:43.281324Z",
     "iopub.status.idle": "2022-08-05T08:29:05.609802Z",
     "shell.execute_reply": "2022-08-05T08:29:05.608758Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting:  Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\n",
      "previous log found: 2022-08-04 23:22\n",
      "difference in execution is: 0.3797 days\n",
      "needed difference to execute: 0.0 days\n",
      "Execute is:  True\n",
      "envs failed to load\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures ðŸ‘‡\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ðŸ¤–\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Slovakia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Barbados\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Turks and Caicos Islands\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Guinea-Bissau\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Serbia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Malawi\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Mauritania\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Tajikistan\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Bahrain\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Tonga\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Slovakia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Croatia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions North Korea\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions British Indian Ocean Territory\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Aruba\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Italy\"\n",
      " > found 17 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 118\n",
      " > 3 usernames filtered out\n",
      " > retweets removed: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/ITA_Italy/figures/ITA_relative_totals.png',\n",
       " 'country_data/ITA_Italy/figures/ITA_GCP_Country_Highlight.png',\n",
       " 'country_data/ITA_Italy/figures/ITA_GCP_1.png',\n",
       " 'country_data/ITA_Italy/figures/ITA_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Timor-Leste\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Sierra Leone\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Indonesia\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 118\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/IDN_Indonesia/figures/IDN_relative_totals.png',\n",
       " 'country_data/IDN_Indonesia/figures/IDN_GCP_Country_Highlight.png',\n",
       " 'country_data/IDN_Indonesia/figures/IDN_GCP_1.png',\n",
       " 'country_data/IDN_Indonesia/figures/IDN_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions French Guiana\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Portugal\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Bhutan\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Nauru\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Iraq\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Madagascar\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions CÃ´te d'Ivoire\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Liberia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Hong Kong\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 119\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/HKG_Hong Kong/figures/HKG_relative_totals.png',\n",
       " 'country_data/HKG_Hong Kong/figures/HKG_GCP_Country_Highlight.png',\n",
       " 'country_data/HKG_Hong Kong/figures/HKG_GCP_1.png',\n",
       " 'country_data/HKG_Hong Kong/figures/HKG_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, True, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "TOOO SOON!!\n",
      "SUCCESS!\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\n",
      "previous log found: 2022-08-04 17:56\n",
      "difference in execution is: 0.6063 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\n",
      "previous log found: 2022-08-04 23:22\n",
      "difference in execution is: 0.3799 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n",
      "starting:  BoliGrafica/Twitter/twitter_post.ipynb\n",
      "previous log found: 2022-08-04 23:22\n",
      "difference in execution is: 0.3799 days\n",
      "needed difference to execute: 0.0042 days\n",
      "Execute is:  True\n",
      "envs failed to load\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'BG1_TWITTER_APIKEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1678/3851052055.py:2\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# est\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m BG1_TWITTER_APIKEY\u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBG1_TWITTER_APIKEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m BG1_TWITTER_APIKEYSECRET \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBG1_TWITTER_APIKEYSECRET\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m BG1_TWITTER_BEARERTOKEN \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBG1_TWITTER_BEARERTOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BG1_TWITTER_APIKEY'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILURE.\n",
      "New log entry successful!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting: \", notebook_path)\n",
    "    \n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = [\"2002-07-16 18:32\",np.nan]\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        import datetime\n",
    "        now = datetime.datetime.now()\n",
    "        last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # FINAL CHECK\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "        \n",
    "    print(\"Execute is: \", str(EXECUTE))\n",
    "    if EXECUTE == True:\n",
    "\n",
    "        \n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"SUCCESS!\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"FAILURE.\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "    else:\n",
    "        print(\"Did not execute nor log\\n\\n\")\n",
    "    return\n",
    "\n",
    "########################################################\n",
    "#\n",
    "\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\", schedule_in_days= .0006/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\", schedule_in_days= 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\", schedule_in_days= 1)\n",
    "SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/Twitter/twitter_post.ipynb\", schedule_in_days= .1/24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be59bc6-1940-45e1-9e81-478b87935bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
