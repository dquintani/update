{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7176ff",
   "metadata": {},
   "source": [
    "# Motherscript.\n",
    "The action to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T12:27:58.326737Z",
     "iopub.status.busy": "2023-04-03T12:27:58.325928Z",
     "iopub.status.idle": "2023-04-03T12:27:58.721265Z",
     "shell.execute_reply": "2023-04-03T12:27:58.720580Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "\n",
    "# envs, just in case\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-03T12:27:58.725882Z",
     "iopub.status.busy": "2023-04-03T12:27:58.725521Z",
     "iopub.status.idle": "2023-04-03T12:28:10.163784Z",
     "shell.execute_reply": "2023-04-03T12:28:10.162487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to check:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\n",
      "previous log found: 2023-04-02 22:12\n",
      "difference in execution is: 0.5944 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb \n",
      "\n",
      "😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\n",
      "previous log found: 2023-04-02 20:14\n",
      "difference in execution is: 0.6764 days\n",
      "needed difference to execute: 0.25 days\n",
      "Executtion:  True ... STARTING NOW\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 503: between bytes timeout",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1780/3578770502.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# load json with country names and codes\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://raw.githubusercontent.com/dquintani/GreenhouseData/master/supplemental/STANDARD_COUNTRY_DICT_ISO3.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m url:\n\u001b[1;32m     16\u001b[0m     STANDARD_COUNTRY_DICT \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(url\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m     18\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 503: between bytes timeout"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... t'was a FAILURE. :(\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb \n",
      "\n",
      "😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/random_fig/random_fig.ipynb\n",
      "previous log found: 2023-04-02 20:14\n",
      "difference in execution is: 0.6765 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/random_fig/random_fig.ipynb \n",
      "\n",
      "😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\n",
      "previous log found: 2023-04-02 12:25\n",
      "difference in execution is: 1.0022 days\n",
      "needed difference to execute: 2 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb \n",
      "\n",
      "😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\n",
      "\n",
      "\n",
      "🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻\n",
      "               FINITO\n",
      "🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting to check: \", notebook_path)\n",
    "    \n",
    "\n",
    "\n",
    "    # if there is no schedule, run immediately\n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "\n",
    "\n",
    "    # else run on a schedule based on last execution time\n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = [\"2002-07-16 18:32\",np.nan]\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        import datetime\n",
    "        now = datetime.datetime.now()\n",
    "        try:\n",
    "            last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        except:\n",
    "            print('check log duplicates for issues here')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # check diff\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE CRITERIA\n",
    "\n",
    "\n",
    "    # EXECUTE TRUE\n",
    "    if EXECUTE == True:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... STARTING NOW\")\n",
    "\n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        # try to run script, if it fails, it fails\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"... t'was a SUCCESS! :)\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"... t'was a FAILURE. :(\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE FALSE\n",
    "    elif EXECUTE == False:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... DID NOT EXECUTE NOR LOG\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Finished: \", notebook_path, \"\\n\\n😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\\n\\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "###################### SCHEDULE #######################\n",
    "########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### BOLIGRAFICA #####\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_covid_replies/covid_reply.ipynb\", schedule_in_days= 12/24)\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\", schedule_in_days=15/24)\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\", schedule_in_days=14/24)\n",
    "\n",
    "###### GREENHOUSE DATA #####\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\", schedule_in_days = 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/random_fig/random_fig.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\", schedule_in_days = 2)\n",
    "\n",
    "\n",
    "print(\"🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻\\n               FINITO\\n🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be59bc6-1940-45e1-9e81-478b87935bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
