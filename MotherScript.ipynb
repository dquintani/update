{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4a0a40-8b47-4681-bb18-f475c239f1ff",
   "metadata": {},
   "source": [
    "Already exists:\n",
    "- Boligrafica Twitter Tweepy\n",
    "- Greenhouse Summon\n",
    "- NOAA Data update GHD\n",
    "\n",
    "Want to create:\n",
    "- GFW - Datos Bolivia Deforestacion / Incendios\n",
    "- Other twitter bots!??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef13b2-37fc-4b5e-8d6f-2f0a3d0982d7",
   "metadata": {},
   "source": [
    "Types of conditions:\n",
    "- Runs on a schedule \n",
    "  - once every week (like boligrafica)\n",
    "  - 4 times a day (like greenhouse summon)\n",
    "- Runs if it has detected updated data (if new data, run)\n",
    "  - Like NOAA data in GHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T16:13:04.362961Z",
     "iopub.status.busy": "2022-07-23T16:13:04.362593Z",
     "iopub.status.idle": "2022-07-23T16:13:04.716769Z",
     "shell.execute_reply": "2022-07-23T16:13:04.712738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython import get_ipython\n",
    "\n",
    "# environmental secrets when working locally\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0908834-aaeb-4413-a8d9-3086674bc2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T16:13:04.720472Z",
     "iopub.status.busy": "2022-07-23T16:13:04.720105Z",
     "iopub.status.idle": "2022-07-23T16:13:04.724833Z",
     "shell.execute_reply": "2022-07-23T16:13:04.724069Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NEW_DATA_RUNNER():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T16:13:04.728057Z",
     "iopub.status.busy": "2022-07-23T16:13:04.727776Z",
     "iopub.status.idle": "2022-07-23T16:13:52.325179Z",
     "shell.execute_reply": "2022-07-23T16:13:52.324357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting:  Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\n",
      "previous log found: 2022-07-23 08:13\n",
      "difference in execution is: 0.3334 days\n",
      "needed difference to execute: 0.25 days\n",
      "Execute is:  True\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures ðŸ‘‡\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ðŸ¤–\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Barbados\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Falkland Islands (Malvinas)\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Peru\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Tuvalu\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Norfolk Island\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Burkina Faso\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Yemen\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Mauritius\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Benin\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Saint BarthÃ©lemy\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Chad\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions United States\"\n",
      " > found 20 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 115\n",
      " > 2 usernames filtered out\n",
      " > retweets removed: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/USA_United States/figures/USA_relative_totals.png',\n",
       " 'country_data/USA_United States/figures/USA_GCP_Country_Highlight.png',\n",
       " 'country_data/USA_United States/figures/USA_GCP_1.png',\n",
       " 'country_data/USA_United States/figures/USA_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Turkey\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Morocco\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions South Korea\"\n",
      " > found 14 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 116\n",
      " > 4 usernames filtered out\n",
      " > retweets removed: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/KOR_South Korea/figures/KOR_relative_totals.png',\n",
       " 'country_data/KOR_South Korea/figures/KOR_GCP_Country_Highlight.png',\n",
       " 'country_data/KOR_South Korea/figures/KOR_GCP_1.png',\n",
       " 'country_data/KOR_South Korea/figures/KOR_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [True, False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Romania\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Angola\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Togo\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Saint Helena, Ascension and Tristan da Cunha\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Lesotho\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Suriname\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Bermuda\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Kazakhstan\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Kuwait\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Lithuania\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Nigeria\"\n",
      " > found 4 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 116\n",
      " > 1 usernames filtered out\n",
      " > retweets removed: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/NGA_Nigeria/figures/NGA_relative_totals.png',\n",
       " 'country_data/NGA_Nigeria/figures/NGA_GCP_Country_Highlight.png',\n",
       " 'country_data/NGA_Nigeria/figures/NGA_GCP_1.png',\n",
       " 'country_data/NGA_Nigeria/figures/NGA_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [True, False, False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [True, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Guyana\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Colombia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Guam\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Finland\"\n",
      " > found 4 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 116\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/FIN_Finland/figures/FIN_relative_totals.png',\n",
       " 'country_data/FIN_Finland/figures/FIN_GCP_Country_Highlight.png',\n",
       " 'country_data/FIN_Finland/figures/FIN_GCP_1.png',\n",
       " 'country_data/FIN_Finland/figures/FIN_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [True, False, False, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "Madagascar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/MDG_Madagascar/figures/MDG_relative_totals.png',\n",
       " 'country_data/MDG_Madagascar/figures/MDG_GCP_Country_Highlight.png',\n",
       " 'country_data/MDG_Madagascar/figures/MDG_GCP_1.png',\n",
       " 'country_data/MDG_Madagascar/figures/MDG_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "country profile tweet SUCCESS!\n",
      "SUCCESS!\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\n",
      "previous log found: 2022-07-22 23:11\n",
      "difference in execution is: 0.7103 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\n",
      "previous log found: 2022-07-22 23:11\n",
      "difference in execution is: 0.7103 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting: \", notebook_path)\n",
    "    \n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = \"2002-07-16 18:32\"\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        now = datetime.datetime.now()\n",
    "        last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # FINAL CHECK\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "        \n",
    "    print(\"Execute is: \", str(EXECUTE))\n",
    "    if EXECUTE == True:\n",
    "\n",
    "        \n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"SUCCESS!\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"FAILURE.\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "    else:\n",
    "        print(\"Did not execute nor log\\n\\n\")\n",
    "    return\n",
    "\n",
    "########################################################\n",
    "#\n",
    "\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\", schedule_in_days= 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\", schedule_in_days= 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\", schedule_in_days= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
