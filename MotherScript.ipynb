{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4a0a40-8b47-4681-bb18-f475c239f1ff",
   "metadata": {},
   "source": [
    "Already exists:\n",
    "- Boligrafica Twitter Tweepy\n",
    "- Greenhouse Summon\n",
    "- NOAA Data update GHD\n",
    "\n",
    "Want to create:\n",
    "- GFW - Datos Bolivia Deforestacion / Incendios\n",
    "- Other twitter bots!??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef13b2-37fc-4b5e-8d6f-2f0a3d0982d7",
   "metadata": {},
   "source": [
    "Types of conditions:\n",
    "- Runs on a schedule \n",
    "  - once every week (like boligrafica)\n",
    "  - 4 times a day (like greenhouse summon)\n",
    "- Runs if it has detected updated data (if new data, run)\n",
    "  - Like NOAA data in GHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T23:10:48.102839Z",
     "iopub.status.busy": "2022-07-31T23:10:48.102027Z",
     "iopub.status.idle": "2022-07-31T23:10:48.426398Z",
     "shell.execute_reply": "2022-07-31T23:10:48.425470Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython import get_ipython\n",
    "\n",
    "# environmental secrets when working locally\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0908834-aaeb-4413-a8d9-3086674bc2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T23:10:48.430384Z",
     "iopub.status.busy": "2022-07-31T23:10:48.430010Z",
     "iopub.status.idle": "2022-07-31T23:10:48.433985Z",
     "shell.execute_reply": "2022-07-31T23:10:48.433267Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NEW_DATA_RUNNER():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-31T23:10:48.438003Z",
     "iopub.status.busy": "2022-07-31T23:10:48.437633Z",
     "iopub.status.idle": "2022-07-31T23:11:09.858983Z",
     "shell.execute_reply": "2022-07-31T23:11:09.858068Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting:  Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\n",
      "previous log found: 2022-07-31 16:12\n",
      "difference in execution is: 0.2908 days\n",
      "needed difference to execute: 0.25 days\n",
      "Execute is:  True\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures ðŸ‘‡\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ðŸ¤–\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions United States Minor Outlying Islands\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Portugal\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Cameroon\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Rwanda\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 94\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/RWA_Rwanda/figures/RWA_relative_totals.png',\n",
       " 'country_data/RWA_Rwanda/figures/RWA_GCP_Country_Highlight.png',\n",
       " 'country_data/RWA_Rwanda/figures/RWA_GCP_1.png',\n",
       " 'country_data/RWA_Rwanda/figures/RWA_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Saint BarthÃ©lemy\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Palestine, State of\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Cayman Islands\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Mauritius\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Cambodia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions China\"\n",
      " > found 20 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 95\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/CHN_China/figures/CHN_relative_totals.png',\n",
       " 'country_data/CHN_China/figures/CHN_GCP_Country_Highlight.png',\n",
       " 'country_data/CHN_China/figures/CHN_GCP_1.png',\n",
       " 'country_data/CHN_China/figures/CHN_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [True, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "TOOO SOON!!\n",
      "SUCCESS!\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\n",
      "previous log found: 2022-07-30 23:10\n",
      "difference in execution is: 1.0008 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  True\n",
      "random_fig generated\n",
      "SUCCESS!\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\n",
      "previous log found: 2022-07-31 08:12\n",
      "difference in execution is: 0.6244 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1891/520225399.py:4: ResourceWarning: unclosed file <_io.BufferedWriter name='random_daily_fig.png'>\n",
      "  open(\"random_daily_fig.png\", \"wb\").write(response.content)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting: \", notebook_path)\n",
    "    \n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = \"2002-07-16 18:32\"\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        now = datetime.datetime.now()\n",
    "        last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # FINAL CHECK\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "        \n",
    "    print(\"Execute is: \", str(EXECUTE))\n",
    "    if EXECUTE == True:\n",
    "\n",
    "        \n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"SUCCESS!\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"FAILURE.\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "    else:\n",
    "        print(\"Did not execute nor log\\n\\n\")\n",
    "    return\n",
    "\n",
    "########################################################\n",
    "#\n",
    "\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\", schedule_in_days= 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\", schedule_in_days= 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\", schedule_in_days= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
