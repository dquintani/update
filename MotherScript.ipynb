{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7176ff",
   "metadata": {},
   "source": [
    "# Motherscript.\n",
    "The action to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T12:28:17.156442Z",
     "iopub.status.busy": "2023-01-02T12:28:17.156010Z",
     "iopub.status.idle": "2023-01-02T12:28:17.485288Z",
     "shell.execute_reply": "2023-01-02T12:28:17.484541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "\n",
    "# envs, just in case\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T12:28:17.488620Z",
     "iopub.status.busy": "2023-01-02T12:28:17.488349Z",
     "iopub.status.idle": "2023-01-02T12:28:23.261816Z",
     "shell.execute_reply": "2023-01-02T12:28:23.261102Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to check:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\n",
      "previous log found: 2023-01-01 12:27\n",
      "difference in execution is: 1.0009 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  True ... STARTING NOW\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1812/3489032676.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipynb\u001b[39;00m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# load json with country names and codes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/dquintani/GreenhouseData/master/supplemental/STANDARD_COUNTRY_DICT_ISO3.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m url:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipynb'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... t'was a FAILURE. :(\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb \n",
      "\n",
      "😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\n",
      "previous log found: 2023-01-01 20:15\n",
      "difference in execution is: 0.6759 days\n",
      "needed difference to execute: 0.25 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "envs failed to load\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures 👇\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! 🤖\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Eswatini\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Antarctica\"\n",
      " > found 8 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 74\n",
      " > 2 usernames filtered out\n",
      " > retweets removed: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1812/3248595385.py:22: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  SELECTED_TWEETS = list(df[\"id\"][:count])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1812/3390178608.py:48\u001b[0m\n\u001b[1;32m     44\u001b[0m tweet_df_filtered \u001b[38;5;241m=\u001b[39m TWEET_FILTER(invalidity_period_days \u001b[38;5;241m=\u001b[39m invalidity_period_days, remove_retweets \u001b[38;5;241m=\u001b[39m remove_retweets)\n\u001b[1;32m     45\u001b[0m SELECTED_TWEETS \u001b[38;5;241m=\u001b[39m TWEET_SELECTOR(count \u001b[38;5;241m=\u001b[39m count, priority \u001b[38;5;241m=\u001b[39m priority, \n\u001b[1;32m     46\u001b[0m                                 remove_col_value \u001b[38;5;241m=\u001b[39m remove_col_value, \n\u001b[1;32m     47\u001b[0m                                 max_followers \u001b[38;5;241m=\u001b[39m max_followers)\n\u001b[0;32m---> 48\u001b[0m media_ids \u001b[38;5;241m=\u001b[39m \u001b[43mTWEET_IMAGE_SAVER_AND_SELECTOR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_global\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m SUCCESS_LIST\u001b[38;5;241m.\u001b[39mappend(TWEET_REPLIER_AND_LOGGER(SELECTED_TWEETS, MESSAGE, media_ids))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess list: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSUCCESS_LIST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/tmp/ipykernel_1812/389341586.py:10\u001b[0m, in \u001b[0;36mTWEET_IMAGE_SAVER_AND_SELECTOR\u001b[0;34m(code, max_count, is_global)\u001b[0m\n\u001b[1;32m      8\u001b[0m res \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m      9\u001b[0m list_dir \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     11\u001b[0m     list_dir\u001b[38;5;241m.\u001b[39mappend(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m])    \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# save randomly\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tree'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... t'was a FAILURE. :(\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb \n",
      "\n",
      "😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/random_fig/random_fig.ipynb\n",
      "previous log found: 2023-01-01 12:27\n",
      "difference in execution is: 1.0009 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "random_fig generated\n",
      "... t'was a SUCCESS! :)\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/random_fig/random_fig.ipynb \n",
      "\n",
      "😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\n",
      "previous log found: 2023-01-01 23:14\n",
      "difference in execution is: 0.5517 days\n",
      "needed difference to execute: 2 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb \n",
      "\n",
      "😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\n",
      "\n",
      "\n",
      "🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻\n",
      "               FINITO\n",
      "🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1812/520225399.py:4: ResourceWarning: unclosed file <_io.BufferedWriter name='random_daily_fig.png'>\n",
      "  open(\"random_daily_fig.png\", \"wb\").write(response.content)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting to check: \", notebook_path)\n",
    "    \n",
    "\n",
    "\n",
    "    # if there is no schedule, run immediately\n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "\n",
    "\n",
    "    # else run on a schedule based on last execution time\n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = [\"2002-07-16 18:32\",np.nan]\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        import datetime\n",
    "        now = datetime.datetime.now()\n",
    "        try:\n",
    "            last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        except:\n",
    "            print('check log duplicates for issues here')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # check diff\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE CRITERIA\n",
    "\n",
    "\n",
    "    # EXECUTE TRUE\n",
    "    if EXECUTE == True:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... STARTING NOW\")\n",
    "\n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        # try to run script, if it fails, it fails\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"... t'was a SUCCESS! :)\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"... t'was a FAILURE. :(\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE FALSE\n",
    "    elif EXECUTE == False:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... DID NOT EXECUTE NOR LOG\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Finished: \", notebook_path, \"\\n\\n😋😋😋😋😋😋😋😋 NEXT 😋😋😋😋😋😋😋😋😋\\n\\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "###################### SCHEDULE #######################\n",
    "########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### BOLIGRAFICA #####\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_covid_replies/covid_reply.ipynb\", schedule_in_days= 12/24)\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\", schedule_in_days=15/24)\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\", schedule_in_days=14/24)\n",
    "\n",
    "###### GREENHOUSE DATA #####\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\", schedule_in_days = 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/random_fig/random_fig.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\", schedule_in_days = 2)\n",
    "\n",
    "\n",
    "print(\"🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻\\n               FINITO\\n🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻🐻\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be59bc6-1940-45e1-9e81-478b87935bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
