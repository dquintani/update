{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4a0a40-8b47-4681-bb18-f475c239f1ff",
   "metadata": {},
   "source": [
    "Already exists:\n",
    "- Boligrafica Twitter Tweepy\n",
    "- Greenhouse Summon\n",
    "- NOAA Data update GHD\n",
    "\n",
    "Want to create:\n",
    "- GFW - Datos Bolivia Deforestacion / Incendios\n",
    "- Other twitter bots!??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef13b2-37fc-4b5e-8d6f-2f0a3d0982d7",
   "metadata": {},
   "source": [
    "Types of conditions:\n",
    "- Runs on a schedule \n",
    "  - once every week (like boligrafica)\n",
    "  - 4 times a day (like greenhouse summon)\n",
    "- Runs if it has detected updated data (if new data, run)\n",
    "  - Like NOAA data in GHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T23:10:05.777680Z",
     "iopub.status.busy": "2022-08-02T23:10:05.777216Z",
     "iopub.status.idle": "2022-08-02T23:10:06.108665Z",
     "shell.execute_reply": "2022-08-02T23:10:06.108075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython import get_ipython\n",
    "\n",
    "# environmental secrets when working locally\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0908834-aaeb-4413-a8d9-3086674bc2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T23:10:06.111960Z",
     "iopub.status.busy": "2022-08-02T23:10:06.111667Z",
     "iopub.status.idle": "2022-08-02T23:10:06.114632Z",
     "shell.execute_reply": "2022-08-02T23:10:06.114033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NEW_DATA_RUNNER():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T23:10:06.117724Z",
     "iopub.status.busy": "2022-08-02T23:10:06.117512Z",
     "iopub.status.idle": "2022-08-02T23:11:00.037884Z",
     "shell.execute_reply": "2022-08-02T23:11:00.037262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting:  Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\n",
      "previous log found: 2022-08-02 16:13\n",
      "difference in execution is: 0.2897 days\n",
      "needed difference to execute: 0.25 days\n",
      "Execute is:  True\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures ðŸ‘‡\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ðŸ¤–\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Iceland\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Japan\"\n",
      " > found 3 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 106\n",
      " > 1 usernames filtered out\n",
      " > retweets removed: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/JPN_Japan/figures/JPN_relative_totals.png',\n",
       " 'country_data/JPN_Japan/figures/JPN_GCP_Country_Highlight.png',\n",
       " 'country_data/JPN_Japan/figures/JPN_GCP_1.png',\n",
       " 'country_data/JPN_Japan/figures/JPN_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Albania\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Dominica\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Rwanda\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 106\n",
      " > 1 usernames filtered out\n",
      " > retweets removed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/RWA_Rwanda/figures/RWA_relative_totals.png',\n",
       " 'country_data/RWA_Rwanda/figures/RWA_GCP_Country_Highlight.png',\n",
       " 'country_data/RWA_Rwanda/figures/RWA_GCP_1.png',\n",
       " 'country_data/RWA_Rwanda/figures/RWA_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False, False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Nepal\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Cabo Verde\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Eswatini\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Niue\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Azerbaijan\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Italy\"\n",
      " > found 17 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 106\n",
      " > 3 usernames filtered out\n",
      " > retweets removed: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/ITA_Italy/figures/ITA_relative_totals.png',\n",
       " 'country_data/ITA_Italy/figures/ITA_GCP_Country_Highlight.png',\n",
       " 'country_data/ITA_Italy/figures/ITA_GCP_1.png',\n",
       " 'country_data/ITA_Italy/figures/ITA_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False, False, False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Monaco\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Belize\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Antigua and Barbuda\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Holy See (Vatican City State)\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Togo\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Bulgaria\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions New Caledonia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Norfolk Island\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Canada\"\n",
      " > found 20 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 106\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/CAN_Canada/figures/CAN_relative_totals.png',\n",
       " 'country_data/CAN_Canada/figures/CAN_GCP_Country_Highlight.png',\n",
       " 'country_data/CAN_Canada/figures/CAN_GCP_1.png',\n",
       " 'country_data/CAN_Canada/figures/CAN_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, False, False, True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Angola\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions United Arab Emirates\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Zimbabwe\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 107\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/ZWE_Zimbabwe/figures/ZWE_relative_totals.png',\n",
       " 'country_data/ZWE_Zimbabwe/figures/ZWE_GCP_Country_Highlight.png',\n",
       " 'country_data/ZWE_Zimbabwe/figures/ZWE_GCP_1.png',\n",
       " 'country_data/ZWE_Zimbabwe/figures/ZWE_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False, False, False, True, False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, False, False, True, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Malawi\"\n",
      " > found 2 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 107\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/MWI_Malawi/figures/MWI_relative_totals.png',\n",
       " 'country_data/MWI_Malawi/figures/MWI_GCP_Country_Highlight.png',\n",
       " 'country_data/MWI_Malawi/figures/MWI_GCP_1.png',\n",
       " 'country_data/MWI_Malawi/figures/MWI_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False, False, False, True, False, False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, False, False, True, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Palestine, State of\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False, True, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Tanzania\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, False, True, False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions South Korea\"\n",
      " > found 4 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 107\n",
      " > 2 usernames filtered out\n",
      " > retweets removed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/KOR_South Korea/figures/KOR_relative_totals.png',\n",
       " 'country_data/KOR_South Korea/figures/KOR_GCP_Country_Highlight.png',\n",
       " 'country_data/KOR_South Korea/figures/KOR_GCP_1.png',\n",
       " 'country_data/KOR_South Korea/figures/KOR_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, False, False, True, False, False, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "TOOO SOON!!\n",
      "SUCCESS!\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\n",
      "previous log found: 2022-08-01 23:12\n",
      "difference in execution is: 0.9993 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\n",
      "previous log found: 2022-08-02 16:13\n",
      "difference in execution is: 0.2903 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting: \", notebook_path)\n",
    "    \n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = \"2002-07-16 18:32\"\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        now = datetime.datetime.now()\n",
    "        last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # FINAL CHECK\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "        \n",
    "    print(\"Execute is: \", str(EXECUTE))\n",
    "    if EXECUTE == True:\n",
    "\n",
    "        \n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"SUCCESS!\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"FAILURE.\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "    else:\n",
    "        print(\"Did not execute nor log\\n\\n\")\n",
    "    return\n",
    "\n",
    "########################################################\n",
    "#\n",
    "\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\", schedule_in_days= 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\", schedule_in_days= 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\", schedule_in_days= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
