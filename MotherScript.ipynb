{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7176ff",
   "metadata": {},
   "source": [
    "# Motherscript.\n",
    "The action to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T12:28:17.156442Z",
     "iopub.status.busy": "2023-01-02T12:28:17.156010Z",
     "iopub.status.idle": "2023-01-02T12:28:17.485288Z",
     "shell.execute_reply": "2023-01-02T12:28:17.484541Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "\n",
    "# envs, just in case\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-02T12:28:17.488620Z",
     "iopub.status.busy": "2023-01-02T12:28:17.488349Z",
     "iopub.status.idle": "2023-01-02T12:28:23.261816Z",
     "shell.execute_reply": "2023-01-02T12:28:23.261102Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to check:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\n",
      "previous log found: 2023-01-01 12:27\n",
      "difference in execution is: 1.0009 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  True ... STARTING NOW\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1812/3489032676.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipynb\u001b[39;00m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# load json with country names and codes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/dquintani/GreenhouseData/master/supplemental/STANDARD_COUNTRY_DICT_ISO3.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m url:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipynb'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... t'was a FAILURE. :(\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\n",
      "previous log found: 2023-01-01 20:15\n",
      "difference in execution is: 0.6759 days\n",
      "needed difference to execute: 0.25 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "envs failed to load\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures ğŸ‘‡\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ğŸ¤–\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Eswatini\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Antarctica\"\n",
      " > found 8 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 74\n",
      " > 2 usernames filtered out\n",
      " > retweets removed: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1812/3248595385.py:22: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  SELECTED_TWEETS = list(df[\"id\"][:count])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1812/3390178608.py:48\u001b[0m\n\u001b[1;32m     44\u001b[0m tweet_df_filtered \u001b[38;5;241m=\u001b[39m TWEET_FILTER(invalidity_period_days \u001b[38;5;241m=\u001b[39m invalidity_period_days, remove_retweets \u001b[38;5;241m=\u001b[39m remove_retweets)\n\u001b[1;32m     45\u001b[0m SELECTED_TWEETS \u001b[38;5;241m=\u001b[39m TWEET_SELECTOR(count \u001b[38;5;241m=\u001b[39m count, priority \u001b[38;5;241m=\u001b[39m priority, \n\u001b[1;32m     46\u001b[0m                                 remove_col_value \u001b[38;5;241m=\u001b[39m remove_col_value, \n\u001b[1;32m     47\u001b[0m                                 max_followers \u001b[38;5;241m=\u001b[39m max_followers)\n\u001b[0;32m---> 48\u001b[0m media_ids \u001b[38;5;241m=\u001b[39m \u001b[43mTWEET_IMAGE_SAVER_AND_SELECTOR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_global\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m SUCCESS_LIST\u001b[38;5;241m.\u001b[39mappend(TWEET_REPLIER_AND_LOGGER(SELECTED_TWEETS, MESSAGE, media_ids))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess list: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSUCCESS_LIST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/tmp/ipykernel_1812/389341586.py:10\u001b[0m, in \u001b[0;36mTWEET_IMAGE_SAVER_AND_SELECTOR\u001b[0;34m(code, max_count, is_global)\u001b[0m\n\u001b[1;32m      8\u001b[0m res \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m      9\u001b[0m list_dir \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     11\u001b[0m     list_dir\u001b[38;5;241m.\u001b[39mappend(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m])    \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# save randomly\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tree'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... t'was a FAILURE. :(\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/random_fig/random_fig.ipynb\n",
      "previous log found: 2023-01-01 12:27\n",
      "difference in execution is: 1.0009 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "random_fig generated\n",
      "... t'was a SUCCESS! :)\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/random_fig/random_fig.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\n",
      "previous log found: 2023-01-01 23:14\n",
      "difference in execution is: 0.5517 days\n",
      "needed difference to execute: 2 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\n",
      "               FINITO\n",
      "ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1812/520225399.py:4: ResourceWarning: unclosed file <_io.BufferedWriter name='random_daily_fig.png'>\n",
      "  open(\"random_daily_fig.png\", \"wb\").write(response.content)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting to check: \", notebook_path)\n",
    "    \n",
    "\n",
    "\n",
    "    # if there is no schedule, run immediately\n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "\n",
    "\n",
    "    # else run on a schedule based on last execution time\n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = [\"2002-07-16 18:32\",np.nan]\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        import datetime\n",
    "        now = datetime.datetime.now()\n",
    "        try:\n",
    "            last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        except:\n",
    "            print('check log duplicates for issues here')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # check diff\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE CRITERIA\n",
    "\n",
    "\n",
    "    # EXECUTE TRUE\n",
    "    if EXECUTE == True:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... STARTING NOW\")\n",
    "\n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        # try to run script, if it fails, it fails\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"... t'was a SUCCESS! :)\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"... t'was a FAILURE. :(\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE FALSE\n",
    "    elif EXECUTE == False:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... DID NOT EXECUTE NOR LOG\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Finished: \", notebook_path, \"\\n\\nğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\\n\\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "###################### SCHEDULE #######################\n",
    "########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### BOLIGRAFICA #####\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_covid_replies/covid_reply.ipynb\", schedule_in_days= 12/24)\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\", schedule_in_days=15/24)\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\", schedule_in_days=14/24)\n",
    "\n",
    "###### GREENHOUSE DATA #####\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\", schedule_in_days = 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/random_fig/random_fig.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\", schedule_in_days = 2)\n",
    "\n",
    "\n",
    "print(\"ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\\n               FINITO\\nğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be59bc6-1940-45e1-9e81-478b87935bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
