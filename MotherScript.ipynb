{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T17:34:25.515544Z",
     "iopub.status.busy": "2022-08-22T17:34:25.515160Z",
     "iopub.status.idle": "2022-08-22T17:34:25.767494Z",
     "shell.execute_reply": "2022-08-22T17:34:25.766832Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "\n",
    "# envs\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d762cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T17:34:25.771055Z",
     "iopub.status.busy": "2022-08-22T17:34:25.770588Z",
     "iopub.status.idle": "2022-08-22T17:34:25.774819Z",
     "shell.execute_reply": "2022-08-22T17:34:25.774344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/runner/work/update/update'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-22T17:34:25.777937Z",
     "iopub.status.busy": "2022-08-22T17:34:25.777512Z",
     "iopub.status.idle": "2022-08-22T17:34:58.125067Z",
     "shell.execute_reply": "2022-08-22T17:34:58.124395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to check:  BoliGrafica/_bots/twitter_covid_replies/covid_reply.ipynb\n",
      "previous log found: 2022-08-22 12:23\n",
      "difference in execution is: 0.2163 days\n",
      "needed difference to execute: 0.5 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  BoliGrafica/_bots/twitter_covid_replies/covid_reply.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\n",
      "previous log found: 2022-07-22 12:24\n",
      "difference in execution is: 31.2156 days\n",
      "needed difference to execute: 0.625 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "dÃ­a de la semana hora local UTC = 0\n",
      "hoy es 2022-08-22\n",
      "Hora actual en UTC = 17:34:25\n",
      "envs failed to load\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pandas/compat/_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1725/2137681347.py:1\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_mun \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBaseDatosAtlasMunicipalODSBolivia2020_Excel.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_mun \u001b[38;5;241m=\u001b[39m df_mun\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_mun \u001b[38;5;241m=\u001b[39m df_mun\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df_mun\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pandas/io/excel/_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m     )\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pandas/io/excel/_base.py:1419\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py:524\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[1;32m    512\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;124;03m        passed to fsspec for appropriate URLs (see ``_get_filepath_or_buffer``)\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pandas/compat/_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... t'was a FAILURE. :(\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\n",
      "previous log found: 2022-07-22 12:24\n",
      "difference in execution is: 31.2156 days\n",
      "needed difference to execute: 0.5833 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "dÃ­a de la semana hora local UTC = 0\n",
      "hoy es 2022-08-22\n",
      "Hora actual en UTC = 17:34:27\n",
      "envs failed to load\n",
      "NV.IND.MANF.KD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state Arizona server backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bolivia: FabricaciÃ³n, valor agregado (constante 2015 US $) \n",
      "\n",
      "Datos vÃ­a la API del Banco Mundial\n",
      "\n",
      "TWEET SUCCESFUL!! \n",
      "... t'was a SUCCESS! :)\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\n",
      "previous log found: 2022-08-21 18:02\n",
      "difference in execution is: 0.9809 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\n",
      "previous log found: 2022-07-22 12:24\n",
      "difference in execution is: 31.2156 days\n",
      "needed difference to execute: 0.25 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "envs failed to load\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures ğŸ‘‡\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ğŸ¤–\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Comoros\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Jordan\"\n",
      " > found 3 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 72\n",
      " > 1 usernames filtered out\n",
      " > retweets removed: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/JOR_Jordan/figures/JOR_relative_totals.png',\n",
       " 'country_data/JOR_Jordan/figures/JOR_GCP_Country_Highlight.png',\n",
       " 'country_data/JOR_Jordan/figures/JOR_GCP_1.png',\n",
       " 'country_data/JOR_Jordan/figures/JOR_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Kuwait\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 72\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/KWT_Kuwait/figures/KWT_relative_totals.png',\n",
       " 'country_data/KWT_Kuwait/figures/KWT_GCP_Country_Highlight.png',\n",
       " 'country_data/KWT_Kuwait/figures/KWT_GCP_1.png',\n",
       " 'country_data/KWT_Kuwait/figures/KWT_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False, False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Sudan\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Bouvet Island\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions United Kingdom\"\n",
      " > found 12 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 72\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/GBR_United Kingdom/figures/GBR_relative_totals.png',\n",
       " 'country_data/GBR_United Kingdom/figures/GBR_GCP_Country_Highlight.png',\n",
       " 'country_data/GBR_United Kingdom/figures/GBR_GCP_1.png',\n",
       " 'country_data/GBR_United Kingdom/figures/GBR_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, False, True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Kiribati\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Macao\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Ã…land Islands\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Guinea-Bissau\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Tokelau\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions France\"\n",
      " > found 6 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 73\n",
      " > 1 usernames filtered out\n",
      " > retweets removed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/FRA_France/figures/FRA_relative_totals.png',\n",
       " 'country_data/FRA_France/figures/FRA_GCP_Country_Highlight.png',\n",
       " 'country_data/FRA_France/figures/FRA_GCP_1.png',\n",
       " 'country_data/FRA_France/figures/FRA_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, False, True, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "... t'was a SUCCESS! :)\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/random_fig/random_fig.ipynb\n",
      "previous log found: 2022-08-21 18:03\n",
      "difference in execution is: 0.9805 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/random_fig/random_fig.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\n",
      "previous log found: 2022-08-21 18:03\n",
      "difference in execution is: 0.9805 days\n",
      "needed difference to execute: 2 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\n",
      "               FINITO\n",
      "ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting to check: \", notebook_path)\n",
    "    \n",
    "\n",
    "\n",
    "    # if there is no schedule, run immediately\n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "\n",
    "\n",
    "    # else run on a schedule based on last execution time\n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = [\"2002-07-16 18:32\",np.nan]\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        import datetime\n",
    "        now = datetime.datetime.now()\n",
    "        last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # check diff\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE?\n",
    "\n",
    "\n",
    "    # EXECUTE TRUE\n",
    "    if EXECUTE == True:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... STARTING NOW\")\n",
    "\n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        # try to run script, if it fails, it fails\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"... t'was a SUCCESS! :)\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"... t'was a FAILURE. :(\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE FALSE\n",
    "    elif EXECUTE == False:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... DID NOT EXECUTE NOR LOG\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Finished: \", notebook_path, \"\\n\\nğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\\n\\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "###################### SCHEDULE #######################\n",
    "########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### BOLIGRAFICA #####\n",
    "SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_covid_replies/covid_reply.ipynb\", schedule_in_days= 12/24)\n",
    "SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\", schedule_in_days=15/24)\n",
    "SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\", schedule_in_days=14/24)\n",
    "\n",
    "###### GREENHOUSE DATA #####\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\", schedule_in_days = 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/random_fig/random_fig.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\", schedule_in_days = 2)\n",
    "\n",
    "\n",
    "print(\"ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\\n               FINITO\\nğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be59bc6-1940-45e1-9e81-478b87935bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3879f593f72178d4cdaa5d992027cc0eafe2075e6c7e6c2da0f0dd376bbd7072"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
