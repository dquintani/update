{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T12:34:20.973517Z",
     "iopub.status.busy": "2022-09-14T12:34:20.973160Z",
     "iopub.status.idle": "2022-09-14T12:34:21.349508Z",
     "shell.execute_reply": "2022-09-14T12:34:21.348516Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "\n",
    "# envs\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d762cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T12:34:21.354154Z",
     "iopub.status.busy": "2022-09-14T12:34:21.353745Z",
     "iopub.status.idle": "2022-09-14T12:34:21.364094Z",
     "shell.execute_reply": "2022-09-14T12:34:21.363102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/runner/work/update/update'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-14T12:34:21.369086Z",
     "iopub.status.busy": "2022-09-14T12:34:21.368717Z",
     "iopub.status.idle": "2022-09-14T12:35:30.219535Z",
     "shell.execute_reply": "2022-09-14T12:35:30.218625Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to check:  BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\n",
      "previous log found: 2022-09-13 12:35\n",
      "difference in execution is: 0.9996 days\n",
      "needed difference to execute: 0.625 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "dÃ­a de la semana hora local UTC = 2\n",
      "hoy es 2022-09-14\n",
      "Hora actual en UTC = 12:34:21\n",
      "envs failed to load\n",
      "\n",
      "MAPA DEL DÃA:\n",
      "Tasa de homicidios registrados, promedio 2015-2017 (por 100,000 habitantes) \n",
      "\n",
      "Municipio mÃ¡s Ã¡lto: Choque Cota con 17.38\n",
      "Municipio mÃ¡s bajo: Santos Mercado con 0.0\n",
      "\n",
      "(Fuente: SDSN Bolivia)\n",
      "\n",
      "TWEET SUCCESFUL!! \n",
      "... t'was a SUCCESS! :)\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\n",
      "previous log found: 2022-09-13 12:35\n",
      "difference in execution is: 0.9996 days\n",
      "needed difference to execute: 0.5833 days\n",
      "Executtion:  True ... STARTING NOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state California server backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dÃ­a de la semana hora local UTC = 2\n",
      "hoy es 2022-09-14\n",
      "Hora actual en UTC = 12:34:25\n",
      "envs failed to load\n",
      "NY.GNP.PCAP.CD\n"
     ]
    },
    {
     "ename": "APIResponseError",
     "evalue": "APIError: JSON decoding error (https://api.worldbank.org/v2/en/sources/2/series/NY.GNP.PCAP.CD?per_page=1000&page=1&format=json)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/requests/models.py:960\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001b[39;00m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# used.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 9 (char 9)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:533\u001b[0m, in \u001b[0;36m_queryAPI\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/requests/models.py:968\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 968\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 9 (char 9)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIResponseError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_1706/3201860860.py:38\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTWEET SUCCESFUL!! \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mpost_wb_fig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/ipykernel_1706/3201860860.py:16\u001b[0m, in \u001b[0;36mpost_wb_fig\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(indicator)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# get indicator title\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[43mwb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtable()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     17\u001b[0m title_plus \u001b[38;5;241m=\u001b[39m ts\u001b[38;5;241m.\u001b[39mgoogle(title, from_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, to_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m title_plus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBolivia: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m title_plus\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/series.py:85\u001b[0m, in \u001b[0;36minfo\u001b[0;34m(id, q, topic, db)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, q\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, topic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, db\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124;03m'''Print a user report of series. This can be time consuming\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    for large databases like the WDI if 'all' series are requested.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:190\u001b[0m, in \u001b[0;36mFeatureset.__init__\u001b[0;34m(self, items, columns)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, items, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124;03m''' can be initialized with any iterable\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m columns \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/series.py:40\u001b[0m, in \u001b[0;36mlist\u001b[0;34m(id, q, topic, db)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m topics\n\u001b[1;32m     38\u001b[0m q,fullSearch \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mqget(q)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m w\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mfeatures(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m'\u001b[39m, w\u001b[38;5;241m.\u001b[39mqueryParam(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m'\u001b[39m, db\u001b[38;5;241m=\u001b[39mdb), db\u001b[38;5;241m=\u001b[39mdb):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mqmatch(q, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m], fullSearch):\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m row\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:322\u001b[0m, in \u001b[0;36mrefetch\u001b[0;34m(url, variables, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m url2 \u001b[38;5;129;01min\u001b[39;00m _refetch_url(url, variables[\u001b[38;5;241m0\u001b[39m], variables[\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 322\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m fetch(url2, params, concepts, lang):\n\u001b[1;32m    323\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m row\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:281\u001b[0m, in \u001b[0;36mfetch\u001b[0;34m(url, params, concepts, lang)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m totalRecords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m recordsRead \u001b[38;5;241m<\u001b[39m totalRecords:\n\u001b[1;32m    280\u001b[0m     url_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(endpoint, lang, url, urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlencode(params_))\n\u001b[0;32m--> 281\u001b[0m     (hdr,result) \u001b[38;5;241m=\u001b[39m \u001b[43m_queryAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m totalRecords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m         totalRecords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(hdr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/wbgapi/__init__.py:535\u001b[0m, in \u001b[0;36m_queryAPI\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    533\u001b[0m     result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIResponseError(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJSON decoding error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    537\u001b[0m hdr \u001b[38;5;241m=\u001b[39m _responseHeader(url, result)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hdr\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mAPIResponseError\u001b[0m: APIError: JSON decoding error (https://api.worldbank.org/v2/en/sources/2/series/NY.GNP.PCAP.CD?per_page=1000&page=1&format=json)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... t'was a FAILURE. :(\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\n",
      "previous log found: 2022-09-13 18:21\n",
      "difference in execution is: 0.7598 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\n",
      "previous log found: 2022-09-13 20:19\n",
      "difference in execution is: 0.6779 days\n",
      "needed difference to execute: 0.25 days\n",
      "Executtion:  True ... STARTING NOW\n",
      "envs failed to load\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures ğŸ‘‡\n",
      "\n",
      "If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ğŸ¤–\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Portugal\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 64\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/PRT_Portugal/figures/PRT_relative_totals.png',\n",
       " 'country_data/PRT_Portugal/figures/PRT_GCP_Country_Highlight.png',\n",
       " 'country_data/PRT_Portugal/figures/PRT_GCP_1.png',\n",
       " 'country_data/PRT_Portugal/figures/PRT_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Paraguay\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions South Sudan\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Bonaire, Sint Eustatius and Saba\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Iraq\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Montserrat\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Eswatini\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions French Polynesia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Russian Federation\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Maldives\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Lesotho\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Georgia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Mozambique\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Saint Kitts and Nevis\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Palau\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Antarctica\"\n",
      " > found 3 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 64\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/ATA_Antarctica/figures/ATA_relative_totals.png',\n",
       " 'country_data/ATA_Antarctica/figures/ATA_GCP_Country_Highlight.png',\n",
       " 'country_data/ATA_Antarctica/figures/ATA_GCP_1.png',\n",
       " 'country_data/ATA_Antarctica/figures/ATA_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 1 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Ukraine\"\n",
      " > found 3 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 65\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/UKR_Ukraine/figures/UKR_relative_totals.png',\n",
       " 'country_data/UKR_Ukraine/figures/UKR_GCP_Country_Highlight.png',\n",
       " 'country_data/UKR_Ukraine/figures/UKR_GCP_1.png',\n",
       " 'country_data/UKR_Ukraine/figures/UKR_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, True, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "... t'was a SUCCESS! :)\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "Finished:  Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/random_fig/random_fig.ipynb\n",
      "previous log found: 2022-09-13 18:21\n",
      "difference in execution is: 0.7601 days\n",
      "needed difference to execute: 1 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/random_fig/random_fig.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "starting to check:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\n",
      "previous log found: 2022-09-13 14:23\n",
      "difference in execution is: 0.9253 days\n",
      "needed difference to execute: 2 days\n",
      "Executtion:  False ... DID NOT EXECUTE NOR LOG\n",
      "Finished:  Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb \n",
      "\n",
      "ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\n",
      "\n",
      "\n",
      "ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\n",
      "               FINITO\n",
      "ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting to check: \", notebook_path)\n",
    "    \n",
    "\n",
    "\n",
    "    # if there is no schedule, run immediately\n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "\n",
    "\n",
    "    # else run on a schedule based on last execution time\n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = [\"2002-07-16 18:32\",np.nan]\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        import datetime\n",
    "        now = datetime.datetime.now()\n",
    "        last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # check diff\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE?\n",
    "\n",
    "\n",
    "    # EXECUTE TRUE\n",
    "    if EXECUTE == True:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... STARTING NOW\")\n",
    "\n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        # try to run script, if it fails, it fails\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"... t'was a SUCCESS! :)\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"... t'was a FAILURE. :(\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # EXECUTE FALSE\n",
    "    elif EXECUTE == False:\n",
    "        print(\"Executtion: \", str(EXECUTE), \"... DID NOT EXECUTE NOR LOG\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Finished: \", notebook_path, \"\\n\\nğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ NEXT ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹ğŸ˜‹\\n\\n\")\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "###################### SCHEDULE #######################\n",
    "########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### BOLIGRAFICA #####\n",
    "# SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_covid_replies/covid_reply.ipynb\", schedule_in_days= 12/24)\n",
    "SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/SDSN/sdsn_map_post.ipynb\", schedule_in_days=15/24)\n",
    "SCHEDULED_RUNNER(notebook_path = \"BoliGrafica/_bots/twitter_bo-indicadores/Banco_Mundial_World_Bank/wbgapi_indicator_post.ipynb\", schedule_in_days=14/24)\n",
    "\n",
    "###### GREENHOUSE DATA #####\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_country_post/country_of_the_day.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/_bots/twitter_greenhouse_summon/greenhouse_summon.ipynb\", schedule_in_days = 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/random_fig/random_fig.ipynb\", schedule_in_days = 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_updates/NOAA_updates.ipynb\", schedule_in_days = 2)\n",
    "\n",
    "\n",
    "print(\"ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\\n               FINITO\\nğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be59bc6-1940-45e1-9e81-478b87935bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3879f593f72178d4cdaa5d992027cc0eafe2075e6c7e6c2da0f0dd376bbd7072"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
