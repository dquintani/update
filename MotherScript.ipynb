{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4a0a40-8b47-4681-bb18-f475c239f1ff",
   "metadata": {},
   "source": [
    "Already exists:\n",
    "- Boligrafica Twitter Tweepy\n",
    "- Greenhouse Summon\n",
    "- NOAA Data update GHD\n",
    "\n",
    "Want to create:\n",
    "- GFW - Datos Bolivia Deforestacion / Incendios\n",
    "- Other twitter bots!??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef13b2-37fc-4b5e-8d6f-2f0a3d0982d7",
   "metadata": {},
   "source": [
    "Types of conditions:\n",
    "- Runs on a schedule \n",
    "  - once every week (like boligrafica)\n",
    "  - 4 times a day (like greenhouse summon)\n",
    "- Runs if it has detected updated data (if new data, run)\n",
    "  - Like NOAA data in GHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59455dd5-248c-4a30-83f0-997ca169ee5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T23:11:50.426064Z",
     "iopub.status.busy": "2022-07-28T23:11:50.425550Z",
     "iopub.status.idle": "2022-07-28T23:11:50.734423Z",
     "shell.execute_reply": "2022-07-28T23:11:50.733755Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython import get_ipython\n",
    "\n",
    "# environmental secrets when working locally\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0908834-aaeb-4413-a8d9-3086674bc2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T23:11:50.738465Z",
     "iopub.status.busy": "2022-07-28T23:11:50.738099Z",
     "iopub.status.idle": "2022-07-28T23:11:50.741672Z",
     "shell.execute_reply": "2022-07-28T23:11:50.740884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NEW_DATA_RUNNER():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb06dfbc-d234-4190-a4bb-dc6c81394684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T23:11:50.745569Z",
     "iopub.status.busy": "2022-07-28T23:11:50.745303Z",
     "iopub.status.idle": "2022-07-28T23:12:23.997825Z",
     "shell.execute_reply": "2022-07-28T23:12:23.996225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting:  Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\n",
      "previous log found: 2022-07-28 16:14\n",
      "difference in execution is: 0.2902 days\n",
      "needed difference to execute: 0.25 days\n",
      "Execute is:  True\n",
      "Iran, Islamic Republic of greenhouse gas emission data and figures ðŸ‘‡\n",
      "\n",
      "If you like this kind of stuff be sure to check out my website for many more datasets and figures! Thank you and have a wonderful day ðŸ¤–\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Trinidad and Tobago\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Eritrea\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Iraq\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Montserrat\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Holy See (Vatican City State)\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Guyana\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Austria\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Tuvalu\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Belize\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Palau\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Guernsey\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Burundi\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Peru\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Nicaragua\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Peru\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions South Africa\"\n",
      " > found 5 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 76\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/ZAF_South Africa/figures/ZAF_relative_totals.png',\n",
       " 'country_data/ZAF_South Africa/figures/ZAF_GCP_Country_Highlight.png',\n",
       " 'country_data/ZAF_South Africa/figures/ZAF_GCP_1.png',\n",
       " 'country_data/ZAF_South Africa/figures/ZAF_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Mauritius\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions China\"\n",
      " > found 20 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 76\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/CHN_China/figures/CHN_relative_totals.png',\n",
       " 'country_data/CHN_China/figures/CHN_GCP_Country_Highlight.png',\n",
       " 'country_data/CHN_China/figures/CHN_GCP_1.png',\n",
       " 'country_data/CHN_China/figures/CHN_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Portugal\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Turkey\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Jamaica\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Mexico\"\n",
      " > found 3 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 77\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/MEX_Mexico/figures/MEX_relative_totals.png',\n",
       " 'country_data/MEX_Mexico/figures/MEX_GCP_Country_Highlight.png',\n",
       " 'country_data/MEX_Mexico/figures/MEX_GCP_1.png',\n",
       " 'country_data/MEX_Mexico/figures/MEX_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, True, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n",
      "TOOO SOON!!\n",
      "SUCCESS!\n",
      "New log entry successful!\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\n",
      "previous log found: 2022-07-28 16:14\n",
      "difference in execution is: 0.2906 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n",
      "starting:  Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\n",
      "previous log found: 2022-07-28 16:15\n",
      "difference in execution is: 0.2899 days\n",
      "needed difference to execute: 1 days\n",
      "Execute is:  False\n",
      "Did not execute nor log\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def SCHEDULED_RUNNER(notebook_path, schedule_in_days = None):\n",
    "    \n",
    "    print(\"starting: \", notebook_path)\n",
    "    \n",
    "    if schedule_in_days == None:\n",
    "        EXECUTE = True\n",
    "        \n",
    "    else:\n",
    "        # check log\n",
    "        log = pd.read_csv(\"log.csv\", index_col=0)\n",
    "        try:\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            print(f\"previous log found: {last_executed}\")\n",
    "        except:\n",
    "            print(\"no log found (first time?) - creating dummy entry (year 2000)\")\n",
    "            log.loc[notebook_path] = \"2002-07-16 18:32\"\n",
    "            \n",
    "            # try again\n",
    "            last_executed = log.loc[notebook_path][\"last_executed\"]\n",
    "            \n",
    "        # get time difference in days\n",
    "        now = datetime.datetime.now()\n",
    "        last_executed = datetime.datetime.strptime(last_executed, '%Y-%m-%d %H:%M')\n",
    "        diff_seconds = now - last_executed\n",
    "        diff_days = diff_seconds.total_seconds() / 60 /60 /24\n",
    "        print(f\"difference in execution is: {round(diff_days,4)} days\")\n",
    "        print(f\"needed difference to execute: {round(schedule_in_days,4)} days\")\n",
    "        \n",
    "        # FINAL CHECK\n",
    "        if diff_days > schedule_in_days:\n",
    "            EXECUTE = True\n",
    "        else:\n",
    "            EXECUTE = False\n",
    "            \n",
    "\n",
    "        \n",
    "    print(\"Execute is: \", str(EXECUTE))\n",
    "    if EXECUTE == True:\n",
    "\n",
    "        \n",
    "        # go to folder to run script locally\n",
    "        folder_path = notebook_path.split(\"/\")[:-1]\n",
    "        os.chdir(\"/\".join(folder_path))\n",
    "\n",
    "        try:\n",
    "            get_ipython().run_line_magic(\"run\", notebook_path.split(\"/\")[-1])\n",
    "            status = \"SUCCESS!\"\n",
    "            print(status)\n",
    "        except:\n",
    "            status = \"FAILURE.\"\n",
    "            print(status)\n",
    "\n",
    "        # go back to root repository\n",
    "        os.chdir(\"\".join([\"../\"] * len(folder_path)))\n",
    "        \n",
    "        \n",
    "        # log\n",
    "        log.loc[notebook_path] = [datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\"), status]\n",
    "        log.to_csv(\"log.csv\")\n",
    "        print(\"New log entry successful!\\n\\n\")\n",
    "    else:\n",
    "        print(\"Did not execute nor log\\n\\n\")\n",
    "    return\n",
    "\n",
    "########################################################\n",
    "#\n",
    "\n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Twitter/GreenhouseSummon.ipynb\", schedule_in_days= 6/24)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/Random_Fig_Daily/Random_Fig_Daily.ipynb\", schedule_in_days= 1)    \n",
    "SCHEDULED_RUNNER(notebook_path = \"Greenhouse_Data/NOAA_Updates/NOAA_Update.ipynb\", schedule_in_days= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85300601-1e1f-4f1c-8b80-bb3d16470da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
