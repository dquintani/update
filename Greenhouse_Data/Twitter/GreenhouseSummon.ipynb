{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2733b807-a40a-47c5-bc0c-b93d54ef7e75",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e069b92f-79e5-4e6b-9adb-c12b361bab6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import urllib.request\n",
    "import random \n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "# load json with country names and codes\n",
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/dquintani/GreenhouseData/master/supplemental/STANDARD_COUNTRY_DICT_ISO3.json\") as url:\n",
    "    STANDARD_COUNTRY_DICT = json.loads(url.read().decode())\n",
    "    \n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdddcf8-5443-4071-98bf-a27be04d1f9d",
   "metadata": {},
   "source": [
    "# Set up tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183fa4b4-d0fe-470e-b37b-411f0a659a96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.api.API at 0x7fde2a546c40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#USING GITHUB ENVS\n",
    "\n",
    "#test\n",
    "GHD_TWITTER_APIKEY= os.environ[\"GHD_TWITTER_APIKEY\"]\n",
    "GHD_TWITTER_APIKEYSECRET = os.environ[\"GHD_TWITTER_APIKEYSECRET\"]\n",
    "\n",
    "GHD_TWITTER_BEARERTOKEN = os.environ[\"GHD_TWITTER_BEARERTOKEN\"]\n",
    "GHD_TWITTER_ACCESSTOKEN = os.environ[\"GHD_TWITTER_ACCESSTOKEN\"]\n",
    "GHD_TWITTER_ACCESSTOKENSECRET = os.environ[\"GHD_TWITTER_ACCESSTOKENSECRET\"]\n",
    "GHD_TWITTER_CLIENTID = os.environ[\"GHD_TWITTER_CLIENTID\"]\n",
    "GHD_TWITTER_CLIENTSECRET = os.environ[\"GHD_TWITTER_CLIENTSECRET\"]\n",
    "\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(GHD_TWITTER_APIKEY, GHD_TWITTER_APIKEYSECRET)\n",
    "auth.set_access_token(GHD_TWITTER_ACCESSTOKEN, GHD_TWITTER_ACCESSTOKENSECRET)\n",
    "\n",
    "# Create API object \n",
    "api = tweepy.API(auth)\n",
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bd22cf-8c6c-400c-bba9-a268fe3ee21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#api.rate_limit_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c049313-6586-4935-b9df-ccefa4e5b9f6",
   "metadata": {},
   "source": [
    "# Retrieve log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11bb9195-2dd6-4fa6-8798-01f694a0a6db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_datetime</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1510165308602040320</th>\n",
       "      <td>2022-01-10 00:00:00.000000</td>\n",
       "      <td>UNEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509886513923989507</th>\n",
       "      <td>2022-03-12 00:00:00.000000</td>\n",
       "      <td>USDOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510559067311206401</th>\n",
       "      <td>2022-04-01 00:00:00.000000</td>\n",
       "      <td>quicoferrer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509179737972912132</th>\n",
       "      <td>2022-04-05 00:35:02.010471</td>\n",
       "      <td>manuvimalassery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508730985550127114</th>\n",
       "      <td>2022-04-05 00:36:33.250239</td>\n",
       "      <td>IBCSOLAR_Int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511751376988164101</th>\n",
       "      <td>2022-04-07 20:59:08.882719</td>\n",
       "      <td>CleanProsperity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511014618914705420</th>\n",
       "      <td>2022-04-07 22:00:57.768164</td>\n",
       "      <td>Mic4815162342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511990439284547591</th>\n",
       "      <td>2022-04-07 22:01:33.711400</td>\n",
       "      <td>Empa_CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511811311554150404</th>\n",
       "      <td>2022-04-08 14:32:45.255261</td>\n",
       "      <td>malamuddy_h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511813253433032706</th>\n",
       "      <td>2022-04-08 14:33:23.688301</td>\n",
       "      <td>mcwhirter_scott</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                reply_datetime         username\n",
       "tweet_id                                                       \n",
       "1510165308602040320 2022-01-10 00:00:00.000000             UNEP\n",
       "1509886513923989507 2022-03-12 00:00:00.000000            USDOT\n",
       "1510559067311206401 2022-04-01 00:00:00.000000      quicoferrer\n",
       "1509179737972912132 2022-04-05 00:35:02.010471  manuvimalassery\n",
       "1508730985550127114 2022-04-05 00:36:33.250239     IBCSOLAR_Int\n",
       "...                                        ...              ...\n",
       "1511751376988164101 2022-04-07 20:59:08.882719  CleanProsperity\n",
       "1511014618914705420 2022-04-07 22:00:57.768164    Mic4815162342\n",
       "1511990439284547591 2022-04-07 22:01:33.711400          Empa_CH\n",
       "1511811311554150404 2022-04-08 14:32:45.255261      malamuddy_h\n",
       "1511813253433032706 2022-04-08 14:33:23.688301  mcwhirter_scott\n",
       "\n",
       "[97 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_log = pd.read_csv(\"id_log.csv\", index_col = 0)\n",
    "id_log.reply_datetime = pd.to_datetime(id_log.reply_datetime)\n",
    "id_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34633fa3-9d1d-4111-8f57-ab5407487504",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e62cdf7f-22f2-42ab-880f-07218fad4637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran, Islamic Republic of greenhouse gas emission data and figures ðŸ‘‡\n",
      "\n",
      "If you like this kind of stuff be sure to check out my website for many more datasets and figures! Thank you and have a wonderful day ðŸ¤–\n"
     ]
    }
   ],
   "source": [
    "def REPLY_MESSAGE_GENERATOR(code, country_place = True):\n",
    "    \n",
    "    # code can be a country or another place (such as global)\n",
    "    if country_place == True:\n",
    "        place = STANDARD_COUNTRY_DICT[code]\n",
    "        link = f\"https://dquintani.github.io/GreenhouseData/country_data/{code}_{STANDARD_COUNTRY_DICT[code]}/\"\n",
    "    elif country_place == False:\n",
    "        place = code\n",
    "        link = \"https://dquintani.github.io/GreenhouseData/global\"\n",
    "        \n",
    "    \n",
    "    text1  = [\n",
    "        f\"{place} greenhouse gas emission data and figures ðŸ‘‡\\n\\n\"\n",
    "    ]\n",
    "    \n",
    "    text2 = [\"\"\n",
    "             # \"Hi there! Thank you for tweeting about greenhouse gas emissions.\\n\\n\",\n",
    "             # \"Hello there! Thank you for tweeting about greenhouse gas emissions.\\n\\n\",\n",
    "             # \"Hi there! Thank you for tweeting about GHG emissions.\\n\\n\",\n",
    "             # \"Hello there! Thank you for tweeting about GHG emissions.\\n\\n\",\n",
    "            ]\n",
    "    \n",
    "    \n",
    "    text3 = [\"\",\n",
    "             \"\",\n",
    "            ]\n",
    "    \n",
    "    text4 = [\"\"\n",
    "            # \"I may hold information you are interested in: \",\n",
    "            #  \"Perhaps I might have something of your interest: \",\n",
    "            #  \"I have something that might be useful to you: \"\n",
    "            ]\n",
    "    \n",
    "    if country_place == True:\n",
    "        text5 = [\"\"\n",
    "            # f\"GHG emission datasets and figures for {place}! \",\n",
    "            # f\"GHG emission figures and lots of datasets for {place}! \"\n",
    "        ]\n",
    "        \n",
    "    elif country_place == False:\n",
    "        text5 = [\"Lots of GHG emission data and figures on a global and international scale!\"]\n",
    "        \n",
    "    text6 = [\n",
    "             \"If you like this kind of stuff be sure to check out my website for many more datasets and figures! Thank you and have a wonderful day ðŸ¤–\",\n",
    "             \"If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ðŸ¤–\",\n",
    "            ]\n",
    "    \n",
    "    \n",
    "\n",
    "    FINAL_MESSAGE = random.choice(text1) + random.choice(text2) + random.choice(text3) + random.choice(text4) + random.choice(text5) + random.choice(text6)# + link.replace(\" \",\"%20\")\n",
    "    \n",
    "    return FINAL_MESSAGE\n",
    "\n",
    "\n",
    "###### ------------------ EXAMPLE --------------------------------------\n",
    "\n",
    "MESSAGE =  REPLY_MESSAGE_GENERATOR(\"IRN\")\n",
    "print(MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c52521-b9fc-4691-8945-7696e3f3fe86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_FINDER(message, search_count = 20, result_type = \"mixed\"):\n",
    "\n",
    "    print(f\" > Searching for {search_count} tweets containing \\\"{message}\\\"\")\n",
    "    \n",
    "    #FIND TWEETS\n",
    "    tweet_list = api.search_tweets(message, \n",
    "                                   result_type=result_type, \n",
    "                                   count=search_count)\n",
    "    \n",
    "    print(f\" > found {len(tweet_list)} tweets\")\n",
    "    \n",
    "    # MAKE DF OF TWEETS\n",
    "    tweet_df = pd.DataFrame(columns=[\"username\",\n",
    "                                      \"followers\",\n",
    "                                      \"date\",\n",
    "                                      \"time\",\n",
    "                                      \"location\",\n",
    "                                      \"verified\",\n",
    "                                      # \"link_and_id\",\n",
    "                                      \"id\",\n",
    "                                      \"message\",\n",
    "                                     ])\n",
    "    for i, j in enumerate(tweet_list):\n",
    "        tweet_df.loc[i] = [j.user.screen_name, \n",
    "                            j.user.followers_count, \n",
    "                            j.created_at.date(), \n",
    "                            j.created_at.time(), \n",
    "                            j.user.location, \n",
    "                            j.user.verified, \n",
    "                            # f\"https://twitter.com/twitter/statuses/{j.id}\",\n",
    "                            j.id,\n",
    "                            api.get_status(j.id, tweet_mode=\"extended\").full_text,\n",
    "                           ]\n",
    "        \n",
    "\n",
    "    #SORT TWEETS BY TIME\n",
    "    tweet_df.sort_values([\"date\",\"time\"], ascending=False)\n",
    "    \n",
    "    return tweet_df\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# tweet_df = TWEET_FINDER(\"global greenhouse gas emissions\", result_type=\"mixed\")\n",
    "# tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3643fe68-fef8-46d9-be00-9ff199f709e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_FILTER(invalidity_period_days = 10, remove_retweets = True):\n",
    "    \n",
    "    ###############################\n",
    "    #      FILTER 1: name log      #\n",
    "    ################################\n",
    "    \n",
    "    # RETRIEVE ID AND NAME LOG\n",
    "    name_log = id_log.copy()\n",
    "    # name_log[\"username\"] = np.nan\n",
    "    # for i in range(len(name_log)):\n",
    "    #     try:\n",
    "    #         name_log.loc[name_log.index[i],\"username\"] = api.get_status(name_log.index[i]).user.screen_name\n",
    "    #     except:\n",
    "    #         pass # this was added because some users were suspended and thus the code failed when trying to fetch their status\n",
    "        \n",
    "    # Current time and invalidity date\n",
    "    now = datetime.datetime.now()\n",
    "    print(f\" > days of invalidity: {invalidity_period_days}\")\n",
    "    invalidity_date = now - datetime.timedelta(days=invalidity_period_days)\n",
    "    \n",
    "    #create list of invalid usernames\n",
    "    name_log_invalid_list = list(name_log[name_log.reply_datetime > invalidity_date].username)\n",
    "    print(f\" > Number of invalids: {len(name_log_invalid_list)}\")\n",
    "    \n",
    "    # Final filter\n",
    "    tweet_df_filtered1 = tweet_df[-tweet_df.username.isin(name_log_invalid_list)]\n",
    "    filter_count = len(tweet_df) - len(tweet_df_filtered1)\n",
    "    print(f\" > {filter_count} usernames filtered out\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    #    FILTER 2: retweeted tweets   #\n",
    "    ##################################$\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    #create new df and add \"is_a_retweet\" columns\n",
    "    tweet_df_filtered2 = tweet_df_filtered1\n",
    "    tweet_df_filtered2[\"is_a_retweet\"] = np.nan\n",
    "        \n",
    "    for i, j in enumerate(tweet_df_filtered1[\"id\"]):\n",
    "        \n",
    "        tweet = api.get_status(j)\n",
    "        \n",
    "        try:\n",
    "            if type(tweet.retweeted_status) == tweepy.models.Status:\n",
    "                tweet_df_filtered2.loc[:,\"is_a_retweet\"][i] = True\n",
    "        except:\n",
    "            tweet_df_filtered2.loc[:,\"is_a_retweet\"][i] = False\n",
    "            \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    \n",
    "    # Filter out tweets that are actually just retweets\n",
    "    if remove_retweets == True:\n",
    "        starting = len(tweet_df_filtered2)\n",
    "        tweet_df_filtered2 = tweet_df_filtered2[tweet_df_filtered2.is_a_retweet==False]\n",
    "        retweets_removed = starting - len(tweet_df_filtered2)\n",
    "        print(f\" > retweets removed: {retweets_removed}\")\n",
    "\n",
    "    \n",
    "    return tweet_df_filtered2\n",
    "    \n",
    "# ----------------------------------------------------------------------------------------------------------------    \n",
    "\n",
    "# tweet_df_filtered = TWEET_FILTER()\n",
    "# tweet_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee0ae0d-d702-4315-9342-1ba969299771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_SELECTOR(count, priority, remove_col_value = [\"column\", \"value\"], max_followers = None):\n",
    "    \n",
    "    SELECTED_TWEETS = []\n",
    "    df = tweet_df_filtered\n",
    "    \n",
    "    #priority\n",
    "    if priority == \"follower_count\":\n",
    "        df = df.sort_values(\"followers\", ascending=False)\n",
    "    if priority == \"verified\":\n",
    "        df = df.sort_values(\"verified\", ascending=False)\n",
    "    \n",
    "    # remove specific value in a columns?\n",
    "    if remove_col_value != [\"column\", \"value\"]:\n",
    "        df = df[df[remove_col_value[0]] != remove_col_value[1]]\n",
    "        print(f\"removed [column, value] = {remove_col_value}\")\n",
    "    \n",
    "    #max followers?\n",
    "    if max_followers != None:\n",
    "        df = df[df.followers < max_followers]\n",
    "        print(f\"max followers: {max_followers}\")\n",
    "    \n",
    "    SELECTED_TWEETS = list(df[\"id\"][:count])\n",
    "    return SELECTED_TWEETS\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# SELECTED_TWEETS = TWEET_SELECTOR(count = 3, \n",
    "#                priority = \"verified\", \n",
    "#                remove_col_value = [\"verified\", False],\n",
    "#                max_followers = 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc97cc76-0714-47c3-97e9-2a7f353e62f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_IMAGE_SAVER_AND_SELECTOR(code, max_count = 4, is_global=False):\n",
    "    \n",
    "    # Setup requests to find images in repository\n",
    "    user = \"dquintani\"\n",
    "    repo = \"GreenhouseData\"\n",
    "    url = f\"https://api.github.com/repos/{user}/{repo}/git/trees/master?recursive=1\"\n",
    "    r = requests.get(url)\n",
    "    res = r.json()\n",
    "    list_dir = []\n",
    "    for file in res[\"tree\"]:\n",
    "        list_dir.append(file[\"path\"])    \n",
    "    \n",
    "    # save randomly\n",
    "    if is_global==True:\n",
    "        path_dir = \"global/\"\n",
    "        list_figs = [i for i in list_dir if i.startswith(path_dir)]\n",
    "        try:\n",
    "            selected_figs_paths = random.sample(list_figs, max_count)\n",
    "        except:\n",
    "            selected_figs_paths = []\n",
    "    \n",
    "    elif is_global == False: #ie is a country code\n",
    "        path_dir = f\"country_data/{code}_{STANDARD_COUNTRY_DICT[code]}/figures/\"\n",
    "        list_figs = [i for i in list_dir if i.startswith(path_dir)]\n",
    "        selected_figs_paths = random.sample(list_figs, max_count)\n",
    "        \n",
    "\n",
    "    #DOWNLOAD AND SAVE THEM\n",
    "    for i,j in enumerate(selected_figs_paths):\n",
    "        image_url = f\"https://dquintani.github.io/GreenhouseData/{j}\"\n",
    "        img_data = requests.get(image_url).content\n",
    "        with open(f'image{i+1}.jpg', 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "        \n",
    "    \n",
    "    media_ids = []\n",
    "    for i in range(max_count):\n",
    "        res = api.media_upload(f\"image{i+1}.jpg\")\n",
    "        media_ids.append(res.media_id)\n",
    "    \n",
    "    print(f\" > saved and selected {max_count} images\")\n",
    "    return media_ids\n",
    "    \n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# TWEET_IMAGE_SAVER_AND_SELECTOR(\"CHE\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbdd4351-58bf-4fe9-84a2-3f9e557c0e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_REPLIER_AND_LOGGER(SELECTED_TWEETS, MESSAGE, media_ids):\n",
    "    \n",
    "    if len(SELECTED_TWEETS)>0:\n",
    "        \n",
    "        for i,j in enumerate(SELECTED_TWEETS):\n",
    "\n",
    "            # SEND TWEET\n",
    "            if len(media_ids)==0:\n",
    "                medi_ids = None\n",
    "                \n",
    "            try:\n",
    "                api.update_status(status = MESSAGE, \n",
    "                                  in_reply_to_status_id = j,\n",
    "                                  auto_populate_reply_metadata=True,\n",
    "                                  media_ids=media_ids)\n",
    "\n",
    "                # LOG TWEET ID (AND THUS USERNAME) and datetime\n",
    "                id_log.loc[j] = [datetime.datetime.now(), api.get_status(j).user.screen_name]\n",
    "\n",
    "                SUCCESS = True\n",
    "                print(\" > TWEET SUCCESSFUL!!\")\n",
    "                \n",
    "            except:\n",
    "                SUCCESS = False\n",
    "                print(\"\\n > OH NO! Something sketchy is going on with that username! Nothing tweeted. False.\")\n",
    "        \n",
    "\n",
    "    if len(SELECTED_TWEETS) == 0:\n",
    "        print(\"\\n > OH NO! NO TWEETS WERE FOUND NOR TWEETED\")\n",
    "        SUCCESS = False\n",
    "    # save log\n",
    "    id_log.to_csv(\"id_log.csv\")\n",
    "    \n",
    "    return SUCCESS\n",
    "    \n",
    "# -------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a826f89-c73f-4dc3-ba5d-461bbf94754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_datetime</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1510165308602040320</th>\n",
       "      <td>2022-01-10 00:00:00.000000</td>\n",
       "      <td>UNEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509886513923989507</th>\n",
       "      <td>2022-03-12 00:00:00.000000</td>\n",
       "      <td>USDOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510559067311206401</th>\n",
       "      <td>2022-04-01 00:00:00.000000</td>\n",
       "      <td>quicoferrer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509179737972912132</th>\n",
       "      <td>2022-04-05 00:35:02.010471</td>\n",
       "      <td>manuvimalassery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508730985550127114</th>\n",
       "      <td>2022-04-05 00:36:33.250239</td>\n",
       "      <td>IBCSOLAR_Int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512362304758767616</th>\n",
       "      <td>2022-04-08 14:38:04.995180</td>\n",
       "      <td>BusinessTrumpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511723445276463105</th>\n",
       "      <td>2022-04-08 14:38:20.972193</td>\n",
       "      <td>ochreblue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512152590599008269</th>\n",
       "      <td>2022-04-08 14:39:51.295187</td>\n",
       "      <td>domipalmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511999785519108096</th>\n",
       "      <td>2022-04-08 14:41:30.218194</td>\n",
       "      <td>EUTenders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511821502127407105</th>\n",
       "      <td>2022-04-08 14:42:09.232961</td>\n",
       "      <td>AlanJMitchell_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                reply_datetime         username\n",
       "tweet_id                                                       \n",
       "1510165308602040320 2022-01-10 00:00:00.000000             UNEP\n",
       "1509886513923989507 2022-03-12 00:00:00.000000            USDOT\n",
       "1510559067311206401 2022-04-01 00:00:00.000000      quicoferrer\n",
       "1509179737972912132 2022-04-05 00:35:02.010471  manuvimalassery\n",
       "1508730985550127114 2022-04-05 00:36:33.250239     IBCSOLAR_Int\n",
       "...                                        ...              ...\n",
       "1512362304758767616 2022-04-08 14:38:04.995180  BusinessTrumpet\n",
       "1511723445276463105 2022-04-08 14:38:20.972193        ochreblue\n",
       "1512152590599008269 2022-04-08 14:39:51.295187       domipalmer\n",
       "1511999785519108096 2022-04-08 14:41:30.218194        EUTenders\n",
       "1511821502127407105 2022-04-08 14:42:09.232961   AlanJMitchell_\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a75cbd-f72b-4ab1-a943-9c43be8a972f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc13d3-e4f9-46d8-806a-9fb1771e92c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f816b-7c6c-4adf-bf90-fc0536c6a6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20922e85-7ce0-4a57-ab75-c2a919409e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854afe1f-3ffe-4ee7-a545-c6bf7dec56cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100af0a-ab69-459f-b8e9-d197a94c589c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621f078-f2b6-4d7e-9842-081f1f4f6598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae7fbf4-b0c5-4a49-82f3-b6d68fbf0159",
   "metadata": {},
   "source": [
    "# EXE: RANDOM COUNTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "318ab43e-d9f1-41d9-90cd-d281e33b256f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Falkland Islands (Malvinas)\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Rwanda\"\n",
      " > found 20 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 100\n",
      " > 1 usernames filtered out\n",
      " > retweets removed: 19\n",
      " > saved and selected 4 images\n",
      "\n",
      " > OH NO! NO TWEETS WERE FOUND NOR TWEETED\n",
      "success list: [False] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Tajikistan\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Maldives\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Lesotho\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [False]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Chile\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 100\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 0\n",
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [False, True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Yemen\"\n",
      " > found 2 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 101\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 1\n",
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [False, True, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n"
     ]
    }
   ],
   "source": [
    "TWEETS_TO_SEND_COUNT = 2\n",
    "\n",
    "SUCCESS_LIST = []\n",
    "while SUCCESS_LIST.count(True) < TWEETS_TO_SEND_COUNT:\n",
    "    \n",
    "    print(\"Starting success list\", SUCCESS_LIST)\n",
    "\n",
    "    # 0. Generate message (required, select False for global):\n",
    "    code = random.choice(list(STANDARD_COUNTRY_DICT.keys()))\n",
    "    country_place = True\n",
    "\n",
    "    # 1. Get the DF:\n",
    "    message = f\"greenhouse gas emissions {STANDARD_COUNTRY_DICT[code]}\" #default: \"\"\n",
    "    search_count = 20 # default: 20\n",
    "    result_type = \"mixed\" #no default, options: mixed, popular, recent\n",
    "\n",
    "    # 2. Filter: \n",
    "    invalidity_period_days = 20 # default 20\n",
    "    remove_retweets = True #default: True\n",
    "\n",
    "\n",
    "    # 3. Select the target tweets by id and count:\n",
    "    count = 1 # no default\n",
    "    priority = \"follower_count\" # no defualt, options: \"follower_count\", \"verified\" \n",
    "    remove_col_value = [\"column\", \"value\"] # default: [\"column\", \"value\"]\n",
    "    max_followers = None # default: None\n",
    "\n",
    "    # 4. Select and save random figures:\n",
    "    max_count = 4 #default 4\n",
    "    is_global = False # default False\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #             EXECUTE                #\n",
    "    ######################################\n",
    "\n",
    "    MESSAGE = REPLY_MESSAGE_GENERATOR(code, country_place = country_place)\n",
    "    tweet_df = TWEET_FINDER(message, search_count = search_count, result_type = result_type)\n",
    "    \n",
    "    if len(tweet_df)==0:\n",
    "        print(\" > empty df: NEXT ITERATION\\n\")\n",
    "        continue\n",
    "        \n",
    "    tweet_df_filtered = TWEET_FILTER(invalidity_period_days = invalidity_period_days, remove_retweets = remove_retweets)\n",
    "    SELECTED_TWEETS = TWEET_SELECTOR(count = count, priority = priority, \n",
    "                                     remove_col_value = remove_col_value, \n",
    "                                     max_followers = max_followers)\n",
    "    media_ids = TWEET_IMAGE_SAVER_AND_SELECTOR(code, max_count = max_count, is_global=is_global)\n",
    "\n",
    "\n",
    "    SUCCESS_LIST.append(TWEET_REPLIER_AND_LOGGER(SELECTED_TWEETS, MESSAGE, media_ids))\n",
    "    print(f\"success list: {SUCCESS_LIST} \\n\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n FINISHED WHILE LOOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dcbefa-ef49-4f67-98bb-0a4f523d19a3",
   "metadata": {},
   "source": [
    "# EXE: TIER COUNTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60bdecd7-01e0-4007-b53d-01abf0ca9f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tier 1\n",
    "TIER_1_COUNTRIES = [\"USA\", \"GBR\", \"DEU\", \"CHN\", \"IND\",\"AUS\", \"CHE\"]\n",
    "TIER_2_COUNTRIES = [\"ITA\", \"IRL\", \"CAN\", \"JPN\", \"BRA\", \"IDN\", \"RUS\",\"ZAF\", \"NZL\", \"FRA\", \"IRN\", \"MEX\", \"TUR\", \"POL\"]\n",
    "TIER_1_AND_2 = TIER_1_COUNTRIES + TIER_2_COUNTRIES\n",
    "# TIER_1_AND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60166ea6-fe3b-42f1-be0d-c415ef9fcf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n"
     ]
    }
   ],
   "source": [
    "TWEETS_TO_SEND_COUNT = 0\n",
    "\n",
    "SUCCESS_LIST = []\n",
    "while SUCCESS_LIST.count(True) < TWEETS_TO_SEND_COUNT:\n",
    "    \n",
    "    print(\"Starting success list\", SUCCESS_LIST)\n",
    "\n",
    "    # 0. Generate message (required, select False for global):\n",
    "    code = random.choice(list(TIER_1_AND_2))\n",
    "    country_place = True\n",
    "\n",
    "    # 1. Get the DF:\n",
    "    message = f\"greenhouse gas emissions {STANDARD_COUNTRY_DICT[code]}\" #default: \"\"\n",
    "    search_count = 20 # default: 30\n",
    "    result_type = \"mixed\" #no default, options: mixed, popular, recent\n",
    "\n",
    "    # 2. Filter: \n",
    "    invalidity_period_days = 20 # default 20\n",
    "    remove_retweets = True #default: True\n",
    "\n",
    "\n",
    "    # 3. Select the target tweets by id and count:\n",
    "    count = 1 # no default\n",
    "    priority = \"follower_count\" # no defualt, options: \"follower_count\", \"verified\" \n",
    "    remove_col_value = [\"column\", \"value\"] # default: [\"column\", \"value\"]\n",
    "    max_followers = None # default: None\n",
    "\n",
    "    # 4. Select and save random figures:\n",
    "    max_count = 4 #default 4\n",
    "    is_global = False # default False\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #             EXECUTE                #\n",
    "    ######################################\n",
    "\n",
    "    MESSAGE = REPLY_MESSAGE_GENERATOR(code, country_place = country_place)\n",
    "    tweet_df = TWEET_FINDER(message, search_count = search_count, result_type = result_type)\n",
    "    tweet_df_filtered = TWEET_FILTER(invalidity_period_days = invalidity_period_days, remove_retweets = remove_retweets)\n",
    "    \n",
    "    if len(tweet_df)==0:\n",
    "        print(\" > empty df: NEXT ITERATION\\n\")\n",
    "        continue\n",
    "        \n",
    "    SELECTED_TWEETS = TWEET_SELECTOR(count = count, priority = priority, \n",
    "                                     remove_col_value = remove_col_value, \n",
    "                                     max_followers = max_followers)\n",
    "    media_ids = TWEET_IMAGE_SAVER_AND_SELECTOR(code, max_count = max_count, is_global=is_global)\n",
    "\n",
    "\n",
    "    SUCCESS_LIST.append(TWEET_REPLIER_AND_LOGGER(SELECTED_TWEETS, MESSAGE, media_ids))\n",
    "    print(f\"success list: {SUCCESS_LIST} \\n\\n\\n\")\n",
    "    \n",
    "print(\"\\n\\n FINISHED WHILE LOOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c9eed-bf24-4e87-9435-98aa5cd8a9a7",
   "metadata": {},
   "source": [
    "# check log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71cdb875-d8c0-42cb-94d8-0555a54ee73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log = pd.read_csv(\"id_log.csv\", index_col=0)\n",
    "# log[\"username\"] = np.nan\n",
    "# for i in range(len(log)):\n",
    "#         try:\n",
    "#             log.loc[log.index[i],\"username\"] = api.get_status(log.index[i]).user.screen_name\n",
    "#         except:\n",
    "#             pass # this was added because some users were suspended and thus the code failed when trying to fetch their status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e43fe3de-954d-43bd-a9a8-2726f918804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log.to_csv(\"id_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83282f-24c8-4a4a-b9ea-3496a8921888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3fcb3-6543-4cd8-9021-2b6a9a2fba6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17327d76-edfa-4bd9-914d-ff732a67ce56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e14608-a320-43f9-a975-4e7691d43057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c9086-414e-4296-b9da-0fc6fc3369aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72df001d-95c5-44b0-ab73-1c16fb97a7f4",
   "metadata": {},
   "source": [
    "# Tweet profile of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "128f1e3b-8fc4-43ab-949a-41cd85e9aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOO SOON!!\n"
     ]
    }
   ],
   "source": [
    "user = \"greenhousedata\"\n",
    "tl = api.user_timeline(screen_name = user, count=30, exclude_replies=True, include_rts=False)\n",
    "latest_tweet = tl[0]\n",
    "latest_tweet_hrs_ago = latest_tweet.created_at\n",
    "latest_tweet_minus_24hr = latest_tweet_hrs_ago  + datetime.timedelta(hours=17)\n",
    "now = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "\n",
    "\n",
    "if latest_tweet_minus_24hr < now:\n",
    "    code = random.choice(list(STANDARD_COUNTRY_DICT.keys()))\n",
    "    print(STANDARD_COUNTRY_DICT[code])\n",
    "    media_ids = TWEET_IMAGE_SAVER_AND_SELECTOR(code, 4)\n",
    "    MESSAGE = f\"Greenhouse Data's country profile of the day: {STANDARD_COUNTRY_DICT[code]}\\n\\nMore greenhouse gas emission data and figures of this country: https://dquintani.github.io/GreenhouseData/country_data/{code}_{STANDARD_COUNTRY_DICT[code]}/\"\n",
    "\n",
    "    api.update_status(status = MESSAGE, \n",
    "                      media_ids=media_ids)\n",
    "    print(\"country profile tweet SUCCESS!\")\n",
    "    \n",
    "else:\n",
    "    print(\"TOOO SOON!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b70d1c-de70-4a49-b637-ecf71fddadeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
