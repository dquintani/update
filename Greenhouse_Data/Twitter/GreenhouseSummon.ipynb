{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2733b807-a40a-47c5-bc0c-b93d54ef7e75",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e069b92f-79e5-4e6b-9adb-c12b361bab6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import urllib.request\n",
    "import random \n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "# load json with country names and codes\n",
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/dquintani/GreenhouseData/master/supplemental/STANDARD_COUNTRY_DICT_ISO3.json\") as url:\n",
    "    STANDARD_COUNTRY_DICT = json.loads(url.read().decode())\n",
    "    \n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1557ae5-1b7f-4aa0-96f5-2d25d594f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "envs loaded\n"
     ]
    }
   ],
   "source": [
    "# environmental secrets when working locally\n",
    "from dotenv import load_dotenv\n",
    "try:\n",
    "    load_dotenv()\n",
    "    load_dotenv(\"../../../\")\n",
    "    print(\"envs loaded\")\n",
    "except:\n",
    "    print(\"envs failed to load\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdddcf8-5443-4071-98bf-a27be04d1f9d",
   "metadata": {},
   "source": [
    "# Set up tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183fa4b4-d0fe-470e-b37b-411f0a659a96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.api.API at 0x7f950cf575b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#USING GITHUB ENVS\n",
    "\n",
    "#test\n",
    "GHD_TWITTER_APIKEY= os.environ[\"GHD_TWITTER_APIKEY\"]\n",
    "GHD_TWITTER_APIKEYSECRET = os.environ[\"GHD_TWITTER_APIKEYSECRET\"]\n",
    "\n",
    "GHD_TWITTER_BEARERTOKEN = os.environ[\"GHD_TWITTER_BEARERTOKEN\"]\n",
    "GHD_TWITTER_ACCESSTOKEN = os.environ[\"GHD_TWITTER_ACCESSTOKEN\"]\n",
    "GHD_TWITTER_ACCESSTOKENSECRET = os.environ[\"GHD_TWITTER_ACCESSTOKENSECRET\"]\n",
    "GHD_TWITTER_CLIENTID = os.environ[\"GHD_TWITTER_CLIENTID\"]\n",
    "GHD_TWITTER_CLIENTSECRET = os.environ[\"GHD_TWITTER_CLIENTSECRET\"]\n",
    "\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(GHD_TWITTER_APIKEY, GHD_TWITTER_APIKEYSECRET)\n",
    "auth.set_access_token(GHD_TWITTER_ACCESSTOKEN, GHD_TWITTER_ACCESSTOKENSECRET)\n",
    "\n",
    "# Create API object \n",
    "api = tweepy.API(auth)\n",
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bd22cf-8c6c-400c-bba9-a268fe3ee21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#api.rate_limit_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c049313-6586-4935-b9df-ccefa4e5b9f6",
   "metadata": {},
   "source": [
    "# Retrieve log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11bb9195-2dd6-4fa6-8798-01f694a0a6db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_datetime</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1510165308602040320</th>\n",
       "      <td>2022-01-10 00:00:00.000000</td>\n",
       "      <td>UNEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509886513923989507</th>\n",
       "      <td>2022-03-12 00:00:00.000000</td>\n",
       "      <td>USDOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510559067311206401</th>\n",
       "      <td>2022-04-01 00:00:00.000000</td>\n",
       "      <td>quicoferrer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509179737972912132</th>\n",
       "      <td>2022-04-05 00:35:02.010471</td>\n",
       "      <td>manuvimalassery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508730985550127114</th>\n",
       "      <td>2022-04-05 00:36:33.250239</td>\n",
       "      <td>IBCSOLAR_Int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552670252013682689</th>\n",
       "      <td>2022-08-02 23:10:59.680888</td>\n",
       "      <td>KoreaEconInst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554452589026189315</th>\n",
       "      <td>2022-08-03 08:15:15.605638</td>\n",
       "      <td>CH4Observatory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554285889404039168</th>\n",
       "      <td>2022-08-03 08:15:29.465037</td>\n",
       "      <td>OmairTAhmad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554535113064579073</th>\n",
       "      <td>2022-08-03 18:21:04.591157</td>\n",
       "      <td>nuclearkenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551985051125948417</th>\n",
       "      <td>2022-08-03 18:21:20.873746</td>\n",
       "      <td>Brianypaulbria1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1629 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                reply_datetime         username\n",
       "tweet_id                                                       \n",
       "1510165308602040320 2022-01-10 00:00:00.000000             UNEP\n",
       "1509886513923989507 2022-03-12 00:00:00.000000            USDOT\n",
       "1510559067311206401 2022-04-01 00:00:00.000000      quicoferrer\n",
       "1509179737972912132 2022-04-05 00:35:02.010471  manuvimalassery\n",
       "1508730985550127114 2022-04-05 00:36:33.250239     IBCSOLAR_Int\n",
       "...                                        ...              ...\n",
       "1552670252013682689 2022-08-02 23:10:59.680888    KoreaEconInst\n",
       "1554452589026189315 2022-08-03 08:15:15.605638   CH4Observatory\n",
       "1554285889404039168 2022-08-03 08:15:29.465037      OmairTAhmad\n",
       "1554535113064579073 2022-08-03 18:21:04.591157     nuclearkenya\n",
       "1551985051125948417 2022-08-03 18:21:20.873746  Brianypaulbria1\n",
       "\n",
       "[1629 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_log = pd.read_csv(\"id_log.csv\", index_col = 0)\n",
    "id_log.reply_datetime = pd.to_datetime(id_log.reply_datetime)\n",
    "id_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34633fa3-9d1d-4111-8f57-ab5407487504",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62cdf7f-22f2-42ab-880f-07218fad4637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran, Islamic Republic of greenhouse gas emission data and figures ðŸ‘‡\n",
      "\n",
      "If you like this kind of stuff be sure to check out my website for many more datasets and figures! Thank you and have a wonderful day ðŸ¤–\n"
     ]
    }
   ],
   "source": [
    "def REPLY_MESSAGE_GENERATOR(code, country_place = True):\n",
    "    \n",
    "    # code can be a country or another place (such as global)\n",
    "    if country_place == True:\n",
    "        place = STANDARD_COUNTRY_DICT[code]\n",
    "        link = f\"https://dquintani.github.io/GreenhouseData/country_data/{code}_{STANDARD_COUNTRY_DICT[code]}/\"\n",
    "    elif country_place == False:\n",
    "        place = code\n",
    "        link = \"https://dquintani.github.io/GreenhouseData/global\"\n",
    "        \n",
    "    \n",
    "    text1  = [\n",
    "        f\"{place} greenhouse gas emission data and figures ðŸ‘‡\\n\\n\"\n",
    "    ]\n",
    "    \n",
    "    text2 = [\"\"\n",
    "             # \"Hi there! Thank you for tweeting about greenhouse gas emissions.\\n\\n\",\n",
    "             # \"Hello there! Thank you for tweeting about greenhouse gas emissions.\\n\\n\",\n",
    "             # \"Hi there! Thank you for tweeting about GHG emissions.\\n\\n\",\n",
    "             # \"Hello there! Thank you for tweeting about GHG emissions.\\n\\n\",\n",
    "            ]\n",
    "    \n",
    "    \n",
    "    text3 = [\"\",\n",
    "             \"\",\n",
    "            ]\n",
    "    \n",
    "    text4 = [\"\"\n",
    "            # \"I may hold information you are interested in: \",\n",
    "            #  \"Perhaps I might have something of your interest: \",\n",
    "            #  \"I have something that might be useful to you: \"\n",
    "            ]\n",
    "    \n",
    "    if country_place == True:\n",
    "        text5 = [\"\"\n",
    "            # f\"GHG emission datasets and figures for {place}! \",\n",
    "            # f\"GHG emission figures and lots of datasets for {place}! \"\n",
    "        ]\n",
    "        \n",
    "    elif country_place == False:\n",
    "        text5 = [\"Lots of GHG emission data and figures on a global and international scale!\"]\n",
    "        \n",
    "    text6 = [\n",
    "             \"If you like this kind of stuff be sure to check out my website for many more datasets and figures! Thank you and have a wonderful day ðŸ¤–\",\n",
    "             \"If interested be sure to check out my website for many more datasets and figures! Thank you and take care! ðŸ¤–\",\n",
    "            ]\n",
    "    \n",
    "    \n",
    "\n",
    "    FINAL_MESSAGE = random.choice(text1) + random.choice(text2) + random.choice(text3) + random.choice(text4) + random.choice(text5) + random.choice(text6)# + link.replace(\" \",\"%20\")\n",
    "    \n",
    "    return FINAL_MESSAGE\n",
    "\n",
    "\n",
    "###### ------------------ EXAMPLE --------------------------------------\n",
    "\n",
    "MESSAGE =  REPLY_MESSAGE_GENERATOR(\"IRN\")\n",
    "print(MESSAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c52521-b9fc-4691-8945-7696e3f3fe86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_FINDER(message, search_count = 20, result_type = \"mixed\"):\n",
    "\n",
    "    print(f\" > Searching for {search_count} tweets containing \\\"{message}\\\"\")\n",
    "    \n",
    "    #FIND TWEETS\n",
    "    tweet_list = api.search_tweets(message, \n",
    "                                   result_type=result_type, \n",
    "                                   count=search_count)\n",
    "    \n",
    "    print(f\" > found {len(tweet_list)} tweets\")\n",
    "    \n",
    "    # MAKE DF OF TWEETS\n",
    "    tweet_df = pd.DataFrame(columns=[\"username\",\n",
    "                                      \"followers\",\n",
    "                                      \"date\",\n",
    "                                      \"time\",\n",
    "                                      \"location\",\n",
    "                                      \"verified\",\n",
    "                                      # \"link_and_id\",\n",
    "                                      \"id\",\n",
    "                                      \"message\",\n",
    "                                     ])\n",
    "    for i, j in enumerate(tweet_list):\n",
    "        tweet_df.loc[i] = [j.user.screen_name, \n",
    "                            j.user.followers_count, \n",
    "                            j.created_at.date(), \n",
    "                            j.created_at.time(), \n",
    "                            j.user.location, \n",
    "                            j.user.verified, \n",
    "                            # f\"https://twitter.com/twitter/statuses/{j.id}\",\n",
    "                            j.id,\n",
    "                            api.get_status(j.id, tweet_mode=\"extended\").full_text,\n",
    "                           ]\n",
    "        \n",
    "\n",
    "    #SORT TWEETS BY TIME\n",
    "    tweet_df.sort_values([\"date\",\"time\"], ascending=False)\n",
    "    \n",
    "    return tweet_df\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# tweet_df = TWEET_FINDER(\"global greenhouse gas emissions\", result_type=\"mixed\")\n",
    "# tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3643fe68-fef8-46d9-be00-9ff199f709e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_FILTER(invalidity_period_days = 10, remove_retweets = True):\n",
    "    \n",
    "    ###############################\n",
    "    #      FILTER 1: name log      #\n",
    "    ################################\n",
    "    \n",
    "    # RETRIEVE ID AND NAME LOG\n",
    "    name_log = id_log.copy()\n",
    "    # name_log[\"username\"] = np.nan\n",
    "    # for i in range(len(name_log)):\n",
    "    #     try:\n",
    "    #         name_log.loc[name_log.index[i],\"username\"] = api.get_status(name_log.index[i]).user.screen_name\n",
    "    #     except:\n",
    "    #         pass # this was added because some users were suspended and thus the code failed when trying to fetch their status\n",
    "        \n",
    "    # Current time and invalidity date\n",
    "    now = datetime.datetime.now()\n",
    "    print(f\" > days of invalidity: {invalidity_period_days}\")\n",
    "    invalidity_date = now - datetime.timedelta(days=invalidity_period_days)\n",
    "    \n",
    "    #create list of invalid usernames\n",
    "    name_log_invalid_list = list(name_log[name_log.reply_datetime > invalidity_date].username)\n",
    "    print(f\" > Number of invalids: {len(name_log_invalid_list)}\")\n",
    "    \n",
    "    # Final filter\n",
    "    tweet_df_filtered1 = tweet_df[-tweet_df.username.isin(name_log_invalid_list)]\n",
    "    filter_count = len(tweet_df) - len(tweet_df_filtered1)\n",
    "    print(f\" > {filter_count} usernames filtered out\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    #    FILTER 2: retweeted tweets   #\n",
    "    ##################################$\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    #create new df and add \"is_a_retweet\" columns\n",
    "    tweet_df_filtered2 = tweet_df_filtered1\n",
    "    tweet_df_filtered2[\"is_a_retweet\"] = np.nan\n",
    "        \n",
    "    for i, j in enumerate(tweet_df_filtered1[\"id\"]):\n",
    "        \n",
    "        tweet = api.get_status(j)\n",
    "        \n",
    "        try:\n",
    "            if type(tweet.retweeted_status) == tweepy.models.Status:\n",
    "                tweet_df_filtered2.loc[:,\"is_a_retweet\"][i] = True\n",
    "        except:\n",
    "            tweet_df_filtered2.loc[:,\"is_a_retweet\"][i] = False\n",
    "            \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    \n",
    "    # Filter out tweets that are actually just retweets\n",
    "    if remove_retweets == True:\n",
    "        starting = len(tweet_df_filtered2)\n",
    "        tweet_df_filtered2 = tweet_df_filtered2[tweet_df_filtered2.is_a_retweet==False]\n",
    "        retweets_removed = starting - len(tweet_df_filtered2)\n",
    "        print(f\" > retweets removed: {retweets_removed}\")\n",
    "\n",
    "    \n",
    "    return tweet_df_filtered2\n",
    "    \n",
    "# ----------------------------------------------------------------------------------------------------------------    \n",
    "\n",
    "# tweet_df_filtered = TWEET_FILTER()\n",
    "# tweet_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee0ae0d-d702-4315-9342-1ba969299771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_SELECTOR(count, priority, remove_col_value = [\"column\", \"value\"], max_followers = None):\n",
    "    \n",
    "    SELECTED_TWEETS = []\n",
    "    df = tweet_df_filtered\n",
    "    \n",
    "    #priority\n",
    "    if priority == \"follower_count\":\n",
    "        df = df.sort_values(\"followers\", ascending=False)\n",
    "    if priority == \"verified\":\n",
    "        df = df.sort_values(\"verified\", ascending=False)\n",
    "    \n",
    "    # remove specific value in a columns?\n",
    "    if remove_col_value != [\"column\", \"value\"]:\n",
    "        df = df[df[remove_col_value[0]] != remove_col_value[1]]\n",
    "        print(f\"removed [column, value] = {remove_col_value}\")\n",
    "    \n",
    "    #max followers?\n",
    "    if max_followers != None:\n",
    "        df = df[df.followers < max_followers]\n",
    "        print(f\"max followers: {max_followers}\")\n",
    "    \n",
    "    SELECTED_TWEETS = list(df[\"id\"][:count])\n",
    "    return SELECTED_TWEETS\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# SELECTED_TWEETS = TWEET_SELECTOR(count = 3, \n",
    "#                priority = \"verified\", \n",
    "#                remove_col_value = [\"verified\", False],\n",
    "#                max_followers = 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc97cc76-0714-47c3-97e9-2a7f353e62f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_IMAGE_SAVER_AND_SELECTOR(code, max_count = 4, is_global=False):\n",
    "    \n",
    "    # Setup requests to find images in repository\n",
    "    user = \"dquintani\"\n",
    "    repo = \"GreenhouseData\"\n",
    "    url = f\"https://api.github.com/repos/{user}/{repo}/git/trees/master?recursive=1\"\n",
    "    r = requests.get(url)\n",
    "    res = r.json()\n",
    "    list_dir = []\n",
    "    for file in res[\"tree\"]:\n",
    "        list_dir.append(file[\"path\"])    \n",
    "    \n",
    "    # save randomly\n",
    "    if is_global==True:\n",
    "        path_dir = \"global/\"\n",
    "        list_figs = [i for i in list_dir if i.startswith(path_dir)]\n",
    "        try:\n",
    "            selected_figs_paths = random.sample(list_figs, max_count)\n",
    "        except:\n",
    "            selected_figs_paths = []\n",
    "    \n",
    "    elif is_global == False: #ie is a country code\n",
    "        path_dir = f\"country_data/{code}_{STANDARD_COUNTRY_DICT[code]}/figures/\"\n",
    "        list_figs = [i for i in list_dir if i.startswith(path_dir)]\n",
    "        \n",
    "        selected_figs_paths = []\n",
    "        # selected_figs_paths = random.sample(list_figs, max_count-1)\n",
    "        selected_figs_paths.append(path_dir + f\"{code}_relative_totals.png\")\n",
    "        selected_figs_paths.append(path_dir + f\"{code}_GCP_Country_Highlight.png\")\n",
    "        selected_figs_paths.append(path_dir + f\"{code}_GCP_1.png\")\n",
    "        selected_figs_paths.append(path_dir + f\"{code}_Minx_top20_subsectors.png\")\n",
    "        display(selected_figs_paths)\n",
    "        \n",
    "\n",
    "    #DOWNLOAD AND SAVE THEM\n",
    "    for i,j in enumerate(selected_figs_paths):\n",
    "        image_url = f\"https://dquintani.github.io/GreenhouseData/{j}\"\n",
    "        img_data = requests.get(image_url).content\n",
    "        with open(f'image{i+1}.jpg', 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "        \n",
    "    \n",
    "    media_ids = []\n",
    "    for i in range(max_count):\n",
    "        try:\n",
    "            res = api.media_upload(f\"image{i+1}.jpg\")\n",
    "            media_ids.append(res.media_id)\n",
    "        except:\n",
    "            pass\n",
    "    print(f\" > saved and selected {len(media_ids)} images\")\n",
    "    return media_ids\n",
    "    \n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# TWEET_IMAGE_SAVER_AND_SELECTOR(\"BES\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbdd4351-58bf-4fe9-84a2-3f9e557c0e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TWEET_REPLIER_AND_LOGGER(SELECTED_TWEETS, MESSAGE, media_ids):\n",
    "    \n",
    "    if len(SELECTED_TWEETS)>0:\n",
    "        \n",
    "        for i,j in enumerate(SELECTED_TWEETS):\n",
    "\n",
    "            # SEND TWEET\n",
    "            if len(media_ids)==0:\n",
    "                medi_ids = None\n",
    "                \n",
    "            try:\n",
    "                api.update_status(status = MESSAGE, \n",
    "                                  in_reply_to_status_id = j,\n",
    "                                  auto_populate_reply_metadata=True,\n",
    "                                  media_ids=media_ids)\n",
    "\n",
    "                # LOG TWEET ID (AND THUS USERNAME) and datetime\n",
    "                id_log.loc[j] = [datetime.datetime.now(), api.get_status(j).user.screen_name]\n",
    "\n",
    "                SUCCESS = True\n",
    "                print(\" > TWEET SUCCESSFUL!!\")\n",
    "                \n",
    "            except:\n",
    "                SUCCESS = False\n",
    "                print(\"\\n > OH NO! Something sketchy is going on with that username! Nothing tweeted. False.\")\n",
    "        \n",
    "\n",
    "    if len(SELECTED_TWEETS) == 0:\n",
    "        print(\"\\n > OH NO! NO TWEETS WERE FOUND NOR TWEETED\")\n",
    "        SUCCESS = False\n",
    "    # save log\n",
    "    id_log.to_csv(\"id_log.csv\")\n",
    "    \n",
    "    return SUCCESS\n",
    "    \n",
    "# -------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a826f89-c73f-4dc3-ba5d-461bbf94754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_datetime</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1510165308602040320</th>\n",
       "      <td>2022-01-10 00:00:00.000000</td>\n",
       "      <td>UNEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509886513923989507</th>\n",
       "      <td>2022-03-12 00:00:00.000000</td>\n",
       "      <td>USDOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510559067311206401</th>\n",
       "      <td>2022-04-01 00:00:00.000000</td>\n",
       "      <td>quicoferrer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509179737972912132</th>\n",
       "      <td>2022-04-05 00:35:02.010471</td>\n",
       "      <td>manuvimalassery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508730985550127114</th>\n",
       "      <td>2022-04-05 00:36:33.250239</td>\n",
       "      <td>IBCSOLAR_Int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548855621755277314</th>\n",
       "      <td>2022-07-19 23:02:08.137098</td>\n",
       "      <td>TheFastMode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546462193687834629</th>\n",
       "      <td>2022-07-20 08:08:36.421388</td>\n",
       "      <td>junkfoodwisdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548274777684463619</th>\n",
       "      <td>2022-07-20 08:08:49.773927</td>\n",
       "      <td>NesEvan9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549161774737305600</th>\n",
       "      <td>2022-07-20 16:07:28.977935</td>\n",
       "      <td>GYBNAfrica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548131320160591873</th>\n",
       "      <td>2022-07-20 16:07:37.404393</td>\n",
       "      <td>ImCrius42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1545 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                reply_datetime         username\n",
       "tweet_id                                                       \n",
       "1510165308602040320 2022-01-10 00:00:00.000000             UNEP\n",
       "1509886513923989507 2022-03-12 00:00:00.000000            USDOT\n",
       "1510559067311206401 2022-04-01 00:00:00.000000      quicoferrer\n",
       "1509179737972912132 2022-04-05 00:35:02.010471  manuvimalassery\n",
       "1508730985550127114 2022-04-05 00:36:33.250239     IBCSOLAR_Int\n",
       "...                                        ...              ...\n",
       "1548855621755277314 2022-07-19 23:02:08.137098      TheFastMode\n",
       "1546462193687834629 2022-07-20 08:08:36.421388   junkfoodwisdom\n",
       "1548274777684463619 2022-07-20 08:08:49.773927         NesEvan9\n",
       "1549161774737305600 2022-07-20 16:07:28.977935       GYBNAfrica\n",
       "1548131320160591873 2022-07-20 16:07:37.404393        ImCrius42\n",
       "\n",
       "[1545 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a75cbd-f72b-4ab1-a943-9c43be8a972f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc13d3-e4f9-46d8-806a-9fb1771e92c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f816b-7c6c-4adf-bf90-fc0536c6a6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20922e85-7ce0-4a57-ab75-c2a919409e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854afe1f-3ffe-4ee7-a545-c6bf7dec56cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100af0a-ab69-459f-b8e9-d197a94c589c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621f078-f2b6-4d7e-9842-081f1f4f6598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae7fbf4-b0c5-4a49-82f3-b6d68fbf0159",
   "metadata": {},
   "source": [
    "# EXE: RANDOM COUNTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "318ab43e-d9f1-41d9-90cd-d281e33b256f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Saint Martin (French part)\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Kuwait\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Saint Lucia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Christmas Island\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list []\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Portugal\"\n",
      " > found 2 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 134\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/PRT_Portugal/figures/PRT_relative_totals.png',\n",
       " 'country_data/PRT_Portugal/figures/PRT_GCP_Country_Highlight.png',\n",
       " 'country_data/PRT_Portugal/figures/PRT_GCP_1.png',\n",
       " 'country_data/PRT_Portugal/figures/PRT_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [True] \n",
      "\n",
      "\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Sri Lanka\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Senegal\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions El Salvador\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Saint BarthÃ©lemy\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions South Georgia and the South Sandwich Islands\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions San Marino\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Bahamas\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Sint Maarten (Dutch part)\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions North Macedonia\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Cuba\"\n",
      " > found 0 tweets\n",
      " > empty df: NEXT ITERATION\n",
      "\n",
      "Starting success list [True]\n",
      " > Searching for 20 tweets containing \"greenhouse gas emissions Qatar\"\n",
      " > found 1 tweets\n",
      " > days of invalidity: 20\n",
      " > Number of invalids: 135\n",
      " > 0 usernames filtered out\n",
      " > retweets removed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['country_data/QAT_Qatar/figures/QAT_relative_totals.png',\n",
       " 'country_data/QAT_Qatar/figures/QAT_GCP_Country_Highlight.png',\n",
       " 'country_data/QAT_Qatar/figures/QAT_GCP_1.png',\n",
       " 'country_data/QAT_Qatar/figures/QAT_Minx_top20_subsectors.png']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > saved and selected 4 images\n",
      " > TWEET SUCCESSFUL!!\n",
      "success list: [True, True] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n"
     ]
    }
   ],
   "source": [
    "TWEETS_TO_SEND_COUNT = 2\n",
    "\n",
    "SUCCESS_LIST = []\n",
    "while SUCCESS_LIST.count(True) < TWEETS_TO_SEND_COUNT:\n",
    "    \n",
    "    print(\"Starting success list\", SUCCESS_LIST)\n",
    "\n",
    "    # 0. Generate message (required, select False for global):\n",
    "    code = random.choice(list(STANDARD_COUNTRY_DICT.keys()))\n",
    "    country_place = True\n",
    "\n",
    "    # 1. Get the DF:\n",
    "    message = f\"greenhouse gas emissions {STANDARD_COUNTRY_DICT[code]}\" #default: \"\"\n",
    "    search_count = 20 # default: 20\n",
    "    result_type = \"mixed\" #no default, options: mixed, popular, recent\n",
    "\n",
    "    # 2. Filter: \n",
    "    invalidity_period_days = 20 # default 20\n",
    "    remove_retweets = True #default: True\n",
    "\n",
    "\n",
    "    # 3. Select the target tweets by id and count:\n",
    "    count = 1 # no default\n",
    "    priority = \"follower_count\" # no defualt, options: \"follower_count\", \"verified\" \n",
    "    remove_col_value = [\"column\", \"value\"] # default: [\"column\", \"value\"]\n",
    "    max_followers = None # default: None\n",
    "\n",
    "    # 4. Select and save random figures:\n",
    "    max_count = 4 #default 4\n",
    "    is_global = False # default False\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #             EXECUTE                #\n",
    "    ######################################\n",
    "\n",
    "    MESSAGE = REPLY_MESSAGE_GENERATOR(code, country_place = country_place)\n",
    "    tweet_df = TWEET_FINDER(message, search_count = search_count, result_type = result_type)\n",
    "    \n",
    "    if len(tweet_df)==0:\n",
    "        print(\" > empty df: NEXT ITERATION\\n\")\n",
    "        continue\n",
    "        \n",
    "    tweet_df_filtered = TWEET_FILTER(invalidity_period_days = invalidity_period_days, remove_retweets = remove_retweets)\n",
    "    SELECTED_TWEETS = TWEET_SELECTOR(count = count, priority = priority, \n",
    "                                     remove_col_value = remove_col_value, \n",
    "                                     max_followers = max_followers)\n",
    "    media_ids = TWEET_IMAGE_SAVER_AND_SELECTOR(code, max_count = max_count, is_global=is_global)\n",
    "\n",
    "\n",
    "    SUCCESS_LIST.append(TWEET_REPLIER_AND_LOGGER(SELECTED_TWEETS, MESSAGE, media_ids))\n",
    "    print(f\"success list: {SUCCESS_LIST} \\n\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n FINISHED WHILE LOOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dcbefa-ef49-4f67-98bb-0a4f523d19a3",
   "metadata": {},
   "source": [
    "# EXE: TIER COUNTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60bdecd7-01e0-4007-b53d-01abf0ca9f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tier 1\n",
    "TIER_1_COUNTRIES = [\"USA\", \"GBR\", \"DEU\", \"CHN\", \"IND\",\"AUS\", \"CHE\"]\n",
    "TIER_2_COUNTRIES = [\"ITA\", \"IRL\", \"CAN\", \"JPN\", \"BRA\", \"IDN\", \"RUS\",\"ZAF\", \"NZL\", \"FRA\", \"IRN\", \"MEX\", \"TUR\", \"POL\"]\n",
    "TIER_1_AND_2 = TIER_1_COUNTRIES + TIER_2_COUNTRIES\n",
    "# TIER_1_AND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60166ea6-fe3b-42f1-be0d-c415ef9fcf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " FINISHED WHILE LOOP\n"
     ]
    }
   ],
   "source": [
    "TWEETS_TO_SEND_COUNT = 0\n",
    "\n",
    "SUCCESS_LIST = []\n",
    "while SUCCESS_LIST.count(True) < TWEETS_TO_SEND_COUNT:\n",
    "    \n",
    "    print(\"Starting success list\", SUCCESS_LIST)\n",
    "\n",
    "    # 0. Generate message (required, select False for global):\n",
    "    code = random.choice(list(TIER_1_AND_2))\n",
    "    country_place = True\n",
    "\n",
    "    # 1. Get the DF:\n",
    "    message = f\"greenhouse gas emissions {STANDARD_COUNTRY_DICT[code]}\" #default: \"\"\n",
    "    search_count = 20 # default: 30\n",
    "    result_type = \"mixed\" #no default, options: mixed, popular, recent\n",
    "\n",
    "    # 2. Filter: \n",
    "    invalidity_period_days = 20 # default 20\n",
    "    remove_retweets = True #default: True\n",
    "\n",
    "\n",
    "    # 3. Select the target tweets by id and count:\n",
    "    count = 1 # no default\n",
    "    priority = \"follower_count\" # no defualt, options: \"follower_count\", \"verified\" \n",
    "    remove_col_value = [\"column\", \"value\"] # default: [\"column\", \"value\"]\n",
    "    max_followers = None # default: None\n",
    "\n",
    "    # 4. Select and save random figures:\n",
    "    max_count = 4 #default 4\n",
    "    is_global = False # default False\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    #             EXECUTE                #\n",
    "    ######################################\n",
    "\n",
    "    MESSAGE = REPLY_MESSAGE_GENERATOR(code, country_place = country_place)\n",
    "    tweet_df = TWEET_FINDER(message, search_count = search_count, result_type = result_type)\n",
    "    tweet_df_filtered = TWEET_FILTER(invalidity_period_days = invalidity_period_days, remove_retweets = remove_retweets)\n",
    "    \n",
    "    if len(tweet_df)==0:\n",
    "        print(\" > empty df: NEXT ITERATION\\n\")\n",
    "        continue\n",
    "        \n",
    "    SELECTED_TWEETS = TWEET_SELECTOR(count = count, priority = priority, \n",
    "                                     remove_col_value = remove_col_value, \n",
    "                                     max_followers = max_followers)\n",
    "    media_ids = TWEET_IMAGE_SAVER_AND_SELECTOR(code, max_count = max_count, is_global=is_global)\n",
    "\n",
    "\n",
    "    SUCCESS_LIST.append(TWEET_REPLIER_AND_LOGGER(SELECTED_TWEETS, MESSAGE, media_ids))\n",
    "    print(f\"success list: {SUCCESS_LIST} \\n\\n\\n\")\n",
    "    \n",
    "print(\"\\n\\n FINISHED WHILE LOOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c9eed-bf24-4e87-9435-98aa5cd8a9a7",
   "metadata": {},
   "source": [
    "# check log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71cdb875-d8c0-42cb-94d8-0555a54ee73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# log = pd.read_csv(\"id_log.csv\", index_col=0)\n",
    "# log[\"username\"] = np.nan\n",
    "# for i in range(len(log)):\n",
    "#         try:\n",
    "#             log.loc[log.index[i],\"username\"] = api.get_status(log.index[i]).user.screen_name\n",
    "#         except:\n",
    "#             pass # this was added because some users were suspended and thus the code failed when trying to fetch their status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e43fe3de-954d-43bd-a9a8-2726f918804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log.to_csv(\"id_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83282f-24c8-4a4a-b9ea-3496a8921888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3fcb3-6543-4cd8-9021-2b6a9a2fba6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17327d76-edfa-4bd9-914d-ff732a67ce56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e14608-a320-43f9-a975-4e7691d43057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c9086-414e-4296-b9da-0fc6fc3369aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72df001d-95c5-44b0-ab73-1c16fb97a7f4",
   "metadata": {},
   "source": [
    "# Tweet profile of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "128f1e3b-8fc4-43ab-949a-41cd85e9aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOO SOON!!\n"
     ]
    }
   ],
   "source": [
    "user = \"greenhousedata\"\n",
    "tl = api.user_timeline(screen_name = user, count=30, exclude_replies=True, include_rts=False)\n",
    "latest_tweet = tl[0]\n",
    "latest_tweet_hrs_ago = latest_tweet.created_at\n",
    "latest_tweet_minus_24hr = latest_tweet_hrs_ago  + datetime.timedelta(hours=17)\n",
    "now = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "\n",
    "\n",
    "if latest_tweet_minus_24hr < now:\n",
    "    code = random.choice(list(STANDARD_COUNTRY_DICT.keys()))\n",
    "    print(STANDARD_COUNTRY_DICT[code])\n",
    "    media_ids = TWEET_IMAGE_SAVER_AND_SELECTOR(code, 4)\n",
    "    MESSAGE = f\"Greenhouse Data's country profile of the day: {STANDARD_COUNTRY_DICT[code]}\\n\\nMore greenhouse gas emission data and figures of this country: https://dquintani.github.io/GreenhouseData/country_data/{code}_{STANDARD_COUNTRY_DICT[code]}/\"\n",
    "\n",
    "    api.update_status(status = MESSAGE, \n",
    "                      media_ids=media_ids)\n",
    "    print(\"country profile tweet SUCCESS!\")\n",
    "    \n",
    "else:\n",
    "    print(\"TOOO SOON!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b70d1c-de70-4a49-b637-ecf71fddadeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
